{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CKO JAR Revision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rpy2.rinterface #ggplot tool\n",
    "from pandas_profiling import ProfileReport\n",
    "import dask.dataframe as dd\n",
    "import wrds\n",
    "import pandasql as ps\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Review TNIC-3 data\n",
    "\n",
    "# ### Import TNIC3 data from Hoberg and Philips data library \n",
    "\n",
    "# # !wget -P ../2_pipeline/ http://hobergphillips.tuck.dartmouth.edu/idata/tnic3_data.zip\n",
    "# # !unzip -q ../2_pipeline/tnic3_data.zip -d ../2_pipeline/ && rm ../2_pipeline/tnic3_data.zip\n",
    "\n",
    "# \"\"\"\n",
    "# Hoberg and Philips TNIC3 database\n",
    "# \"\"\"\n",
    "# tnic = pd.read_csv('/Users/ohn0000/Dropbox/Project/cko/0_data/external/tnic3_data.txt', \n",
    "#                    delimiter='\\t', header=0, index_col=['gvkey1', 'year', 'gvkey2'])\n",
    "# tnic.dropna(inplace=True)\n",
    "\n",
    "# ### Subset to 20-closest competitors\n",
    "\n",
    "# # tnic_industry = tnic.groupby(level=['gvkey1', 'year'])[\"score\"].nlargest(20).reset_index(level=[0,1], drop=True)\n",
    "# # tnic_industry = tnic_industry.to_frame(name='score')\n",
    "# # tnic_industry.to_pickle('../2_pipeline/tnic_industry.pkl')\n",
    "# tnic_industry = pd.read_pickle('../2_pipeline/tnic_industry.pkl')\n",
    "\n",
    "# ```tnic_industry``` still has firm-years with less than 20 competitors.\n",
    "\n",
    "# # \"\"\"\n",
    "# # Require at least 20 closest competitors\n",
    "# # \"\"\"\n",
    "# # tnicind_sub = tnic.groupby(level=['gvkey1', 'year'])[\"score\"].filter(lambda x: x.size == 20)\n",
    "# # tnicind_sub = tnicind_sub.to_frame(name='score')\n",
    "\n",
    "# \"\"\"\n",
    "# tnic_industry['gvkey1'] = tnic_industry['gvkey1'].apply(lambda x: str(x).zfill(6))\n",
    "# tnic_industry['gvkey2'] = tnic_industry['gvkey2'].apply(lambda x: str(x).zfill(6))\n",
    "# \"\"\"\n",
    "\n",
    "# Remeber that _year_ in __tnic_industry__ is the base year for identifying close competitors. Accordingly, _lead1_ is the M&A year and _lead2_ is the year following M&A.\n",
    "\n",
    "# Readme_tnic3.txt explains that _year_ equals the first four digits of the __compustat__ _datadate_.\n",
    "\n",
    "# ### Shift years in __tnic_industry__ to get _lead1_ and _lead2_ similarity scores\n",
    "\n",
    "# tnic_industry.rename(columns={'score':'score_0'}, inplace=True)\n",
    "\n",
    "# for i in range(1,3):\n",
    "#     colname = 'score' + '_' + str(i)\n",
    "#     tnic_industry['score'] = np.NaN\n",
    "#     tnic_industry.index = tnic_industry.index.set_levels(tnic_industry.index.levels[1] + 1, level=1)\n",
    "#     tnic_industry.update(tnic)\n",
    "#     tnic_industry.rename(columns={'score':colname}, inplace=True)\n",
    "\n",
    "# tnic_industry.reset_index(inplace=True)\n",
    "# tnic_industry[\"year\"] -= 2\n",
    "# tnic_industry.set_index([\"gvkey1\", \"year\", \"gvkey2\"], inplace=True)\n",
    "\n",
    "# tnic_industry.to_pickle('../2_pipeline/tnic_industry.pkl')\n",
    "\n",
    "# ### Run __*tnic_industry.py*__ on _WRDS_ to update lead scores\n",
    "\n",
    "# Many of the _lead1_ and _lead2_ values are missing. Grab these values from __TNIC_Advanced__ uploaded on _WRDS_. \n",
    "\n",
    "# # !scp ../2_pipeline/tnic_industry.pkl tnic_industry.py $WRDS:~\n",
    "\n",
    "# ### Download updated __*tnic_industry*__ file from WRDS\n",
    "\n",
    "# # !scp $WRDS:/scratch/ou/hohn/tnic_ind_update.pkl ../2_pipeline/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnic_industry = pd.read_pickle('../2_pipeline/tnic_ind_update.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average TNIC similarity score across 20-closest competitors.  \n",
    "Remeber that in __TNIC_ALL__ most of the scores equals to zero. The _z\\__ might be the more suitable.\n",
    "- Close pair in t0 not appearing in t1 or t2 is meaningful.\n",
    "- __BE CAREFUL__ of year 2016 and 2017. __TNIC is available only up to 2017__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sim = tnic_industry.groupby(level=['gvkey1','year']).mean()\n",
    "avg_sim = avg_sim.join(tnic_industry.groupby(level=['gvkey1','year']).count().add_prefix(\"n_\"))\n",
    "avg_sim = avg_sim.join(tnic_industry.fillna(0).groupby(level=['gvkey1','year']).mean().add_prefix(\"z_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109791"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(avg_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab COMPUSTAT _datadate_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revise here if _avg\\_sim_ needs additional COMPUSTAT variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading library list...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "db = wrds.Connection(wrds_username='yaera')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_query = \"\"\"\n",
    "select distinct gvkey, datadate, fyear, indfmt, sale\n",
    "from comp.funda\n",
    "where consol = %(consol)s and indfmt in %(indfmt)s \n",
    "    and datafmt = %(datafmt)s and popsrc = %(popsrc)s\n",
    "    and curcd in %(curcd)s\n",
    "order by gvkey, fyear\n",
    "\"\"\"\n",
    "\n",
    "parm = {'consol':('C'), 'indfmt' : ('INDL', 'FS'), 'datafmt': ('STD'), 'popsrc' : ('D'), 'curcd' : ('USD', 'CAD')}\n",
    "comp = db.raw_sql(comp_query, date_cols=['datadate'], params=parm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp['fyear'] = comp['fyear'].astype('int16')\n",
    "comp['year'] = comp['datadate'].dt.year.astype('int16')\n",
    "\n",
    "comp['gvkey1'] = pd.to_numeric(comp['gvkey']).astype('int64')\n",
    "comp.drop(columns='gvkey', inplace=True)\n",
    "\n",
    "comp.set_index(['gvkey1', 'fyear'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not sure how TNIC deals fiscal years where fyear are differenct but\n",
    "year are the same. Assume the lastest datadate within _year_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadate = comp[~comp.index.duplicated(keep='last')][['datadate', 'year']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sim = pd.merge(avg_sim, datadate, \n",
    "                 left_index=True, \n",
    "                 right_on=['gvkey1', 'year'], how='left').drop_duplicates(['gvkey1', 'year'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sim = avg_sim[avg_sim['datadate'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TNIC data not missing _datadate_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109757"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(avg_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = list(avg_sim)\n",
    "col = col[-4:] + col[:-4]\n",
    "avg_sim = avg_sim[col].sort_values(['gvkey1', 'year', 'datadate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab _permno_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revise here if _avg\\_sim_ needs additional CRSP variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query= \"\"\"\n",
    "select gvkey, liid as iid, lpermno as permno, linkdt, linkenddt\n",
    "from crsp.ccmxpf_linktable\n",
    "where linktype in %(type)s and linkprim in %(prim)s and usedflag = 1\n",
    "\"\"\"\n",
    "\n",
    "parm = {'type':('LU', 'LC'), 'prim':('P', 'C')}\n",
    "linktable = db.raw_sql(sql_query, date_cols=['linkdt', 'linkenddt'], params=parm)\n",
    "\n",
    "linktable['gvkey'] = pd.to_numeric(linktable['gvkey'])\n",
    "linktable['permno'] = pd.to_numeric(linktable['permno']).astype('int64')\n",
    "linktable['iid'] = linktable['iid'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "enddt = pd.to_datetime('2020-01-07 00:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "linktable['linkenddt'] = linktable['linkenddt'].fillna(value = enddt)\n",
    "linktable['linkenddt'] = linktable['linkenddt'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(':memory:')\n",
    "avg_sim.to_sql('avg_sim', conn, index=False)\n",
    "linktable.to_sql('linktable', conn, index=False)\n",
    "\n",
    "qry = '''\n",
    "    select  \n",
    "        avg_sim.*, linktable.permno\n",
    "    from\n",
    "        avg_sim left join linktable on\n",
    "        avg_sim.datadate between linkdt and linkenddt and avg_sim.gvkey1 = linktable.gvkey\n",
    "    '''\n",
    "df = pd.read_sql_query(qry, conn)\n",
    "df['permno'] = df['permno'].astype('Int64')\n",
    "df['datadate'] = df['datadate'].astype('datetime64[ns]')\n",
    "\n",
    "df[df['permno'].isna()].to_sql('df', conn, index=False)\n",
    "\n",
    "qry = '''\n",
    "    select\n",
    "        a.*, b.gvkey1, b.datadate\n",
    "        from linktable a join df b\n",
    "        on \n",
    "            a.gvkey = b.gvkey1\n",
    "'''\n",
    "aug = pd.read_sql_query(qry, conn)\n",
    "\n",
    "aug.to_sql('aug', conn, index=False)\n",
    "qry = '''\n",
    "    select gvkey1, permno, iid, min(linkdt) as linkdt, max(linkenddt) as linkenddt\n",
    "    from aug\n",
    "    group by gvkey1, permno, iid\n",
    "    order by gvkey1, linkdt\n",
    "'''\n",
    "\n",
    "df = df.merge(aug[aug['iid'].isin(['01','02'])].rename(columns={'permno':'permno1'})[['gvkey1', 'permno1']], \n",
    "         left_on = ['gvkey1'], right_on=['gvkey1'], how='left')\n",
    "df['permno'] = np.where(df['permno'].isna(), df['permno1'], df['permno'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(['gvkey1', 'year']).drop(columns='permno1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = list(df)\n",
    "col.insert(2, col.pop(col.index('permno')))\n",
    "df = df[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ohn0000/.local/share/virtualenvs/cko-psiKzMQ6/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/ohn0000/.local/share/virtualenvs/cko-psiKzMQ6/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/ohn0000/.local/share/virtualenvs/cko-psiKzMQ6/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ohn0000/.local/share/virtualenvs/cko-psiKzMQ6/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "df['dt_s1'] = np.where(df['year'] == 2017, np.NaN, df['score_1'] - df['score_0'])\n",
    "df['dt_s2'] = np.where(df['year'] == 2017, np.NaN, df['score_2'] - df['score_1'])\n",
    "df['dt_z1'] = np.where(df['year'] == 2017, np.NaN, df['z_score_1'] - df['z_score_0'])\n",
    "df['dt_z2'] = np.where(df['year'] >= 2016, np.NaN, df['z_score_2'] - df['z_score_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(['gvkey1', 'year'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link SDC to COMPUSTAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>master_deal_no</th>\n",
       "      <th>dateann</th>\n",
       "      <th>tmanames</th>\n",
       "      <th>amanames</th>\n",
       "      <th>a_lockup_pct</th>\n",
       "      <th>a_postmerge_own_pct</th>\n",
       "      <th>aacount</th>\n",
       "      <th>advcount</th>\n",
       "      <th>afinancial</th>\n",
       "      <th>albofirm</th>\n",
       "      <th>...</th>\n",
       "      <th>sf</th>\n",
       "      <th>purpose_text</th>\n",
       "      <th>anation</th>\n",
       "      <th>anationcode</th>\n",
       "      <th>tnation</th>\n",
       "      <th>tnationcode</th>\n",
       "      <th>tpublic</th>\n",
       "      <th>apublic</th>\n",
       "      <th>tsicp</th>\n",
       "      <th>tticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11801020.0</td>\n",
       "      <td>1986-10-24</td>\n",
       "      <td>ABA Groups Inc</td>\n",
       "      <td>Information Resources Inc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>Priv.</td>\n",
       "      <td>Public</td>\n",
       "      <td>7379</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11801020.0</td>\n",
       "      <td>1986-10-24</td>\n",
       "      <td>ABA Groups Inc</td>\n",
       "      <td>Information Resources Inc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>Priv.</td>\n",
       "      <td>Public</td>\n",
       "      <td>7379</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11801020.0</td>\n",
       "      <td>1986-10-24</td>\n",
       "      <td>ABA Groups Inc</td>\n",
       "      <td>Information Resources Inc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>Priv.</td>\n",
       "      <td>Public</td>\n",
       "      <td>7379</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11801020.0</td>\n",
       "      <td>1986-10-24</td>\n",
       "      <td>ABA Groups Inc</td>\n",
       "      <td>Information Resources Inc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>Priv.</td>\n",
       "      <td>Public</td>\n",
       "      <td>7379</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11801020.0</td>\n",
       "      <td>1986-10-24</td>\n",
       "      <td>ABA Groups Inc</td>\n",
       "      <td>Information Resources Inc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>Priv.</td>\n",
       "      <td>Public</td>\n",
       "      <td>7379</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   master_deal_no     dateann        tmanames                   amanames  \\\n",
       "0      11801020.0  1986-10-24  ABA Groups Inc  Information Resources Inc   \n",
       "1      11801020.0  1986-10-24  ABA Groups Inc  Information Resources Inc   \n",
       "2      11801020.0  1986-10-24  ABA Groups Inc  Information Resources Inc   \n",
       "3      11801020.0  1986-10-24  ABA Groups Inc  Information Resources Inc   \n",
       "4      11801020.0  1986-10-24  ABA Groups Inc  Information Resources Inc   \n",
       "\n",
       "   a_lockup_pct  a_postmerge_own_pct  aacount  advcount afinancial albofirm  \\\n",
       "0           NaN                  NaN      NaN       NaN         No       No   \n",
       "1           NaN                  NaN      NaN       NaN         No       No   \n",
       "2           NaN                  NaN      NaN       NaN         No       No   \n",
       "3           NaN                  NaN      NaN       NaN         No       No   \n",
       "4           NaN                  NaN      NaN       NaN         No       No   \n",
       "\n",
       "   ...    sf purpose_text        anation anationcode        tnation  \\\n",
       "0  ...  None         None  United States          US  United States   \n",
       "1  ...  None         None  United States          US  United States   \n",
       "2  ...  None         None  United States          US  United States   \n",
       "3  ...  None         None  United States          US  United States   \n",
       "4  ...  None         None  United States          US  United States   \n",
       "\n",
       "  tnationcode tpublic apublic tsicp tticker  \n",
       "0          US   Priv.  Public  7379    None  \n",
       "1          US   Priv.  Public  7379    None  \n",
       "2          US   Priv.  Public  7379    None  \n",
       "3          US   Priv.  Public  7379    None  \n",
       "4          US   Priv.  Public  7379    None  \n",
       "\n",
       "[5 rows x 176 columns]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compmna.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdc_query = \"\"\"\n",
    "select *\n",
    "from \n",
    "    sdc.ma_details\n",
    "where APUBLIC = %(APUBLIC)s and STATUSCODE = %(STATUSCODE)s \n",
    "    and ANATIONCODE = %(ANATIONCODE)s and FORM in %(FORM)s\n",
    "order by MASTER_DEAL_NO\n",
    "\"\"\"\n",
    "# Public aquirer\n",
    "# Completed deals\n",
    "# US acquirer\n",
    "# M&A deals\n",
    "\n",
    "parm = {'APUBLIC':('Public'), 'STATUSCODE' : ('C'), 'ANATIONCODE': ('US'), 'FORM' : ('Merger','Acquisition')}\n",
    "compmna = db.raw_sql(sdc_query, date_cols=['DATEANN', 'DATEEFF','DATEFIN'], params=parm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['master_deal_no', 'amanames', 'acusip', 'apublic', 'attitude', 'dateann', 'dateeff',\n",
    "           'datefin', 'ebitltm', 'amv','entval', 'bookvalue', 'eqval','mv', 'netass', 'niltm',\n",
    "           'pct_cash', 'pct_stk', 'pct_other', 'pct_unknown', 'pr',\n",
    "           'rankval', 'salesltm', 'tmanames', 'tnationcode', 'tpublic', 'master_cusip', 'tticker']\n",
    "compmna = compmna[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "master_deal_no          category\n",
       "amanames                  object\n",
       "acusip                  category\n",
       "apublic                 category\n",
       "attitude                category\n",
       "dateann           datetime64[ns]\n",
       "dateeff           datetime64[ns]\n",
       "datefin           datetime64[ns]\n",
       "ebitltm                  float64\n",
       "amv                      float64\n",
       "entval                   float64\n",
       "bookvalue                float64\n",
       "eqval                    float64\n",
       "mv                       float64\n",
       "netass                   float64\n",
       "niltm                    float64\n",
       "pct_cash                 float64\n",
       "pct_stk                  float64\n",
       "pct_other                float64\n",
       "pct_unknown              float64\n",
       "pr                       float64\n",
       "rankval                  float64\n",
       "salesltm                 float64\n",
       "tmanames                  object\n",
       "tnationcode             category\n",
       "tpublic                 category\n",
       "master_cusip            category\n",
       "tticker                   object\n",
       "dtype: object"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compmna.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ohn0000/.local/share/virtualenvs/cko-psiKzMQ6/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "compmna['master_deal_no'] = compmna['master_deal_no'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>master_deal_no</th>\n",
       "      <th>amanames</th>\n",
       "      <th>acusip</th>\n",
       "      <th>apublic</th>\n",
       "      <th>attitude</th>\n",
       "      <th>dateann</th>\n",
       "      <th>dateeff</th>\n",
       "      <th>datefin</th>\n",
       "      <th>ebitltm</th>\n",
       "      <th>amv</th>\n",
       "      <th>...</th>\n",
       "      <th>pct_other</th>\n",
       "      <th>pct_unknown</th>\n",
       "      <th>pr</th>\n",
       "      <th>rankval</th>\n",
       "      <th>salesltm</th>\n",
       "      <th>tmanames</th>\n",
       "      <th>tnationcode</th>\n",
       "      <th>tpublic</th>\n",
       "      <th>master_cusip</th>\n",
       "      <th>tticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11801020</td>\n",
       "      <td>Information Resources Inc</td>\n",
       "      <td>456905</td>\n",
       "      <td>Public</td>\n",
       "      <td>Friendly</td>\n",
       "      <td>1986-10-24</td>\n",
       "      <td>1987-01-22</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>271.688</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.9</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABA Groups Inc</td>\n",
       "      <td>US</td>\n",
       "      <td>Priv.</td>\n",
       "      <td>00036T</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11801020</td>\n",
       "      <td>Information Resources Inc</td>\n",
       "      <td>456905</td>\n",
       "      <td>Public</td>\n",
       "      <td>Friendly</td>\n",
       "      <td>1986-10-24</td>\n",
       "      <td>1987-01-22</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>271.688</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.9</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABA Groups Inc</td>\n",
       "      <td>US</td>\n",
       "      <td>Priv.</td>\n",
       "      <td>00036T</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11801020</td>\n",
       "      <td>Information Resources Inc</td>\n",
       "      <td>456905</td>\n",
       "      <td>Public</td>\n",
       "      <td>Friendly</td>\n",
       "      <td>1986-10-24</td>\n",
       "      <td>1987-01-22</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>271.688</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.9</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABA Groups Inc</td>\n",
       "      <td>US</td>\n",
       "      <td>Priv.</td>\n",
       "      <td>00036T</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11801020</td>\n",
       "      <td>Information Resources Inc</td>\n",
       "      <td>456905</td>\n",
       "      <td>Public</td>\n",
       "      <td>Friendly</td>\n",
       "      <td>1986-10-24</td>\n",
       "      <td>1987-01-22</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>271.688</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.9</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABA Groups Inc</td>\n",
       "      <td>US</td>\n",
       "      <td>Priv.</td>\n",
       "      <td>00036T</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11801020</td>\n",
       "      <td>Information Resources Inc</td>\n",
       "      <td>456905</td>\n",
       "      <td>Public</td>\n",
       "      <td>Friendly</td>\n",
       "      <td>1986-10-24</td>\n",
       "      <td>1987-01-22</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>271.688</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.9</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABA Groups Inc</td>\n",
       "      <td>US</td>\n",
       "      <td>Priv.</td>\n",
       "      <td>00036T</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136519</th>\n",
       "      <td>3504523020</td>\n",
       "      <td>Meritor Inc</td>\n",
       "      <td>59039C</td>\n",
       "      <td>Public</td>\n",
       "      <td>Friendly</td>\n",
       "      <td>2020-01-16</td>\n",
       "      <td>2020-01-16</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Transportation Power Inc</td>\n",
       "      <td>US</td>\n",
       "      <td>Priv.</td>\n",
       "      <td>9J9929</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136520</th>\n",
       "      <td>3504523020</td>\n",
       "      <td>Meritor Inc</td>\n",
       "      <td>59039C</td>\n",
       "      <td>Public</td>\n",
       "      <td>Friendly</td>\n",
       "      <td>2020-01-16</td>\n",
       "      <td>2020-01-16</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Transportation Power Inc</td>\n",
       "      <td>US</td>\n",
       "      <td>Priv.</td>\n",
       "      <td>9J9929</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136521</th>\n",
       "      <td>3506714020</td>\n",
       "      <td>B2 Digital Inc</td>\n",
       "      <td>11777J</td>\n",
       "      <td>Public</td>\n",
       "      <td>Friendly</td>\n",
       "      <td>2019-12-12</td>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ONE More Gym LLC</td>\n",
       "      <td>US</td>\n",
       "      <td>Priv.</td>\n",
       "      <td>0K1091</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136522</th>\n",
       "      <td>3506714020</td>\n",
       "      <td>B2 Digital Inc</td>\n",
       "      <td>11777J</td>\n",
       "      <td>Public</td>\n",
       "      <td>Friendly</td>\n",
       "      <td>2019-12-12</td>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ONE More Gym LLC</td>\n",
       "      <td>US</td>\n",
       "      <td>Priv.</td>\n",
       "      <td>0K1091</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136523</th>\n",
       "      <td>3506714020</td>\n",
       "      <td>B2 Digital Inc</td>\n",
       "      <td>11777J</td>\n",
       "      <td>Public</td>\n",
       "      <td>Friendly</td>\n",
       "      <td>2019-12-12</td>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ONE More Gym LLC</td>\n",
       "      <td>US</td>\n",
       "      <td>Priv.</td>\n",
       "      <td>0K1091</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136524 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        master_deal_no                   amanames  acusip apublic  attitude  \\\n",
       "0             11801020  Information Resources Inc  456905  Public  Friendly   \n",
       "1             11801020  Information Resources Inc  456905  Public  Friendly   \n",
       "2             11801020  Information Resources Inc  456905  Public  Friendly   \n",
       "3             11801020  Information Resources Inc  456905  Public  Friendly   \n",
       "4             11801020  Information Resources Inc  456905  Public  Friendly   \n",
       "...                ...                        ...     ...     ...       ...   \n",
       "136519      3504523020                Meritor Inc  59039C  Public  Friendly   \n",
       "136520      3504523020                Meritor Inc  59039C  Public  Friendly   \n",
       "136521      3506714020             B2 Digital Inc  11777J  Public  Friendly   \n",
       "136522      3506714020             B2 Digital Inc  11777J  Public  Friendly   \n",
       "136523      3506714020             B2 Digital Inc  11777J  Public  Friendly   \n",
       "\n",
       "          dateann    dateeff datefin  ebitltm      amv  ...  pct_other  \\\n",
       "0      1986-10-24 1987-01-22     NaT      NaN  271.688  ...        NaN   \n",
       "1      1986-10-24 1987-01-22     NaT      NaN  271.688  ...        NaN   \n",
       "2      1986-10-24 1987-01-22     NaT      NaN  271.688  ...        NaN   \n",
       "3      1986-10-24 1987-01-22     NaT      NaN  271.688  ...        NaN   \n",
       "4      1986-10-24 1987-01-22     NaT      NaN  271.688  ...        NaN   \n",
       "...           ...        ...     ...      ...      ...  ...        ...   \n",
       "136519 2020-01-16 2020-01-16     NaT      NaN      NaN  ...        NaN   \n",
       "136520 2020-01-16 2020-01-16     NaT      NaN      NaN  ...        NaN   \n",
       "136521 2019-12-12 2020-01-06     NaT      NaN      NaN  ...        NaN   \n",
       "136522 2019-12-12 2020-01-06     NaT      NaN      NaN  ...        NaN   \n",
       "136523 2019-12-12 2020-01-06     NaT      NaN      NaN  ...        NaN   \n",
       "\n",
       "        pct_unknown    pr  rankval  salesltm                  tmanames  \\\n",
       "0               NaN  13.9     12.0       NaN            ABA Groups Inc   \n",
       "1               NaN  13.9     12.0       NaN            ABA Groups Inc   \n",
       "2               NaN  13.9     12.0       NaN            ABA Groups Inc   \n",
       "3               NaN  13.9     12.0       NaN            ABA Groups Inc   \n",
       "4               NaN  13.9     12.0       NaN            ABA Groups Inc   \n",
       "...             ...   ...      ...       ...                       ...   \n",
       "136519          NaN   NaN      NaN       NaN  Transportation Power Inc   \n",
       "136520          NaN   NaN      NaN       NaN  Transportation Power Inc   \n",
       "136521          NaN   NaN      NaN       NaN          ONE More Gym LLC   \n",
       "136522          NaN   NaN      NaN       NaN          ONE More Gym LLC   \n",
       "136523          NaN   NaN      NaN       NaN          ONE More Gym LLC   \n",
       "\n",
       "        tnationcode  tpublic  master_cusip  tticker  \n",
       "0                US    Priv.        00036T     None  \n",
       "1                US    Priv.        00036T     None  \n",
       "2                US    Priv.        00036T     None  \n",
       "3                US    Priv.        00036T     None  \n",
       "4                US    Priv.        00036T     None  \n",
       "...             ...      ...           ...      ...  \n",
       "136519           US    Priv.        9J9929     None  \n",
       "136520           US    Priv.        9J9929     None  \n",
       "136521           US    Priv.        0K1091     None  \n",
       "136522           US    Priv.        0K1091     None  \n",
       "136523           US    Priv.        0K1091     None  \n",
       "\n",
       "[136524 rows x 28 columns]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compmna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-201-d1cc564c2e34>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-201-d1cc564c2e34>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    compmna.loc[, col] = pd.to_numeric(compmna[, col]).astype(float)\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# category variables\n",
    "for col in ['master_deal_no', 'acusip', 'apublic', 'attitude', 'tnationcode', 'tpublic', 'master_cusip']:\n",
    "    compmna[col] = compmna[col].astype('category')\n",
    "\n",
    "var = list(compmna)\n",
    "# floats\n",
    "for col in var[8:23]:\n",
    "#     # ENTVAL 'M' Form of Deal is Merger 'P' Deal Status is Partial\n",
    "#     compmna[col] = np.where(compmna[col].astype(str).isin(['nan', 'None', 'P', 'M']), np.NaN, compmna[col].astype(str).str.replace(',',''))\n",
    "    compmna.loc[col] = pd.to_numeric(compmna[, col]).astype(float)\n",
    "\n",
    "# date variables\n",
    "for col in ['dateann', 'dateeff', 'datefin']:\n",
    "    compmna[col] = compmna[col].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .dt accessor with datetimelike values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-195-0e54af876974>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcompmna\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompmna\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompmna\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dateeff'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1995\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcompmna\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dateeff'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m2017\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'last'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/share/virtualenvs/cko-psiKzMQ6/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5173\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5174\u001b[0m         ):\n\u001b[0;32m-> 5175\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5176\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5177\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/cko-psiKzMQ6/lib/python3.7/site-packages/pandas/core/accessor.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0;31m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0maccessor_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;31m# Replace the property with the accessor object. Inspired by:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;31m# http://www.pydanny.com/cached-property.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/cko-psiKzMQ6/lib/python3.7/site-packages/pandas/core/indexes/accessors.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data)\u001b[0m\n\u001b[1;32m    341\u001b[0m             \u001b[0;32mpass\u001b[0m  \u001b[0;31m# we raise an attribute error anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can only use .dt accessor with datetimelike \"\u001b[0m \u001b[0;34m\"values\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use .dt accessor with datetimelike values"
     ]
    }
   ],
   "source": [
    "compmna = compmna[(compmna['dateeff'].dt.year >= 1995) & (compmna['dateeff'].dt.year <= 2017)].drop_duplicates(keep='last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of SDC observations with non-overlapping deal ID's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19835"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(compmna)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SDC and Compustat Link File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The link file is from [Michael Ewens](https://github.com/michaelewens/SDC-to-Compustat-Mapping.git). Cite papers below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "@article{phillips2013r,\n",
    "  title={R\\&D and the Incentives from Merger and Acquisition Activity},\n",
    "  author={Phillips, Gordon M and Zhdanov, Alexei},\n",
    "  journal={The Review of Financial Studies},\n",
    "  volume={26},\n",
    "  number={1},\n",
    "  pages={34--78},\n",
    "  year={2013},\n",
    "  publisher={Society for Financial Studies}\n",
    "  }\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "@article{ewensPetersWang2018,\n",
    " title={Acquisition prices and the measurement of intangible capital},\n",
    " author={Ewens, Michael and Peters, Ryan and Wang, Sean},\n",
    " journal={Working Paper}\n",
    " year={2018}\n",
    " }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdc_link = pd.read_csv('/Users/ohn0000/Dropbox/Project/cko/0_data/external/dealnum_to_gvkey.csv', \n",
    "                       dtype={'DealNumber':'Int64', 'agvkey':'Int64', 'tgvkey':'Int64'}, \n",
    "                       index_col='DealNumber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "compmna['MASTER_DEAL_NO'] = pd.to_numeric(compmna['MASTER_DEAL_NO']).astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agvkey</th>\n",
       "      <th>tgvkey</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DealNumber</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11942020</th>\n",
       "      <td>3342</td>\n",
       "      <td>1634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12014020</th>\n",
       "      <td>10379</td>\n",
       "      <td>1960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12049020</th>\n",
       "      <td>3485</td>\n",
       "      <td>2053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12152020</th>\n",
       "      <td>12672</td>\n",
       "      <td>2560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12188020</th>\n",
       "      <td>1899</td>\n",
       "      <td>2756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3128101120</th>\n",
       "      <td>28742</td>\n",
       "      <td>14170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3136151020</th>\n",
       "      <td>24720</td>\n",
       "      <td>4156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138151020</th>\n",
       "      <td>10466</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3146627072</th>\n",
       "      <td>26590</td>\n",
       "      <td>14169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3149704960</th>\n",
       "      <td>24660</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128443 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            agvkey  tgvkey\n",
       "DealNumber                \n",
       "11942020      3342    1634\n",
       "12014020     10379    1960\n",
       "12049020      3485    2053\n",
       "12152020     12672    2560\n",
       "12188020      1899    2756\n",
       "...            ...     ...\n",
       "3128101120   28742   14170\n",
       "3136151020   24720    4156\n",
       "3138151020   10466     NaN\n",
       "3146627072   26590   14169\n",
       "3149704960   24660     NaN\n",
       "\n",
       "[128443 rows x 2 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdc_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128443"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sdc_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MASTER_DEAL_NO</th>\n",
       "      <th>AMANAMES</th>\n",
       "      <th>ACUSIP</th>\n",
       "      <th>APUBLIC</th>\n",
       "      <th>ATTITUDE</th>\n",
       "      <th>DATEANN</th>\n",
       "      <th>DATEEFF</th>\n",
       "      <th>DATEFIN</th>\n",
       "      <th>EBITLTM</th>\n",
       "      <th>AMV</th>\n",
       "      <th>...</th>\n",
       "      <th>PR</th>\n",
       "      <th>RANKVAL</th>\n",
       "      <th>SALESLTM</th>\n",
       "      <th>TMANAMES</th>\n",
       "      <th>TNATIONCODE</th>\n",
       "      <th>TPUBLIC</th>\n",
       "      <th>MASTER_CUSIP</th>\n",
       "      <th>TTICKER</th>\n",
       "      <th>agvkey</th>\n",
       "      <th>tgvkey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>411673020</td>\n",
       "      <td>International Remote Imaging</td>\n",
       "      <td>460259</td>\n",
       "      <td>Public</td>\n",
       "      <td>Friendly</td>\n",
       "      <td>1992-09-30</td>\n",
       "      <td>1995-06-14</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>19.64</td>\n",
       "      <td>3.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LDA Systems Inc</td>\n",
       "      <td>US</td>\n",
       "      <td>Priv.</td>\n",
       "      <td>50182J</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>312002020</td>\n",
       "      <td>Managed Health Benefits Corp</td>\n",
       "      <td>561660</td>\n",
       "      <td>Public</td>\n",
       "      <td>Friendly</td>\n",
       "      <td>1992-12-16</td>\n",
       "      <td>1995-05-19</td>\n",
       "      <td>1993-07-31</td>\n",
       "      <td>-2.323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.464</td>\n",
       "      <td>0.684</td>\n",
       "      <td>Avitar Inc</td>\n",
       "      <td>US</td>\n",
       "      <td>Public</td>\n",
       "      <td>053794</td>\n",
       "      <td>AVIT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>333750040</td>\n",
       "      <td>MICROS Systems Inc</td>\n",
       "      <td>594901</td>\n",
       "      <td>Public</td>\n",
       "      <td>Friendly</td>\n",
       "      <td>1993-05-13</td>\n",
       "      <td>1995-11-30</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fidelio Software GmbH</td>\n",
       "      <td>WG</td>\n",
       "      <td>Priv.</td>\n",
       "      <td>31574A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>360715020</td>\n",
       "      <td>Peer Review Analysis Inc</td>\n",
       "      <td>705478</td>\n",
       "      <td>Public</td>\n",
       "      <td>Friendly</td>\n",
       "      <td>1993-08-13</td>\n",
       "      <td>1995-03-24</td>\n",
       "      <td>1993-03-31</td>\n",
       "      <td>-2.579</td>\n",
       "      <td>19.682</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.351</td>\n",
       "      <td>8.122</td>\n",
       "      <td>Core Management Inc</td>\n",
       "      <td>US</td>\n",
       "      <td>Priv.</td>\n",
       "      <td>21867H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>381944020</td>\n",
       "      <td>Northern Trust Corp</td>\n",
       "      <td>665859</td>\n",
       "      <td>Public</td>\n",
       "      <td>Friendly</td>\n",
       "      <td>1993-12-20</td>\n",
       "      <td>1995-03-31</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Beach One Financial Services</td>\n",
       "      <td>US</td>\n",
       "      <td>Priv.</td>\n",
       "      <td>07338A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17734</th>\n",
       "      <td>3184713020</td>\n",
       "      <td>American Woodmark Corp</td>\n",
       "      <td>030506</td>\n",
       "      <td>Public</td>\n",
       "      <td>Friendly</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>2017-12-29</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1510.429</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1080.147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RSI Home Products Inc</td>\n",
       "      <td>US</td>\n",
       "      <td>Priv.</td>\n",
       "      <td>74978X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17931</th>\n",
       "      <td>3185616040</td>\n",
       "      <td>Westinghouse Air Brake Tech</td>\n",
       "      <td>929740</td>\n",
       "      <td>Public</td>\n",
       "      <td>Friendly</td>\n",
       "      <td>2017-12-04</td>\n",
       "      <td>2017-12-04</td>\n",
       "      <td>2017-05-31</td>\n",
       "      <td>6.876</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.036</td>\n",
       "      <td>Melett Ltd</td>\n",
       "      <td>UK</td>\n",
       "      <td>Priv.</td>\n",
       "      <td>0H3415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>3185792040</td>\n",
       "      <td>Scientific Learning Corp</td>\n",
       "      <td>808760</td>\n",
       "      <td>Public</td>\n",
       "      <td>Friendly</td>\n",
       "      <td>2017-12-04</td>\n",
       "      <td>2017-12-04</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brain Maps Tech Co Ltd</td>\n",
       "      <td>CH</td>\n",
       "      <td>Priv.</td>\n",
       "      <td>0H3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>3192870020</td>\n",
       "      <td>Verint Systems Inc</td>\n",
       "      <td>92343X</td>\n",
       "      <td>Public</td>\n",
       "      <td>Friendly</td>\n",
       "      <td>2017-12-19</td>\n",
       "      <td>2017-12-19</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Next It Corp</td>\n",
       "      <td>US</td>\n",
       "      <td>Priv.</td>\n",
       "      <td>0H8195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2235</th>\n",
       "      <td>3193908020</td>\n",
       "      <td>LCNB Corp</td>\n",
       "      <td>50181P</td>\n",
       "      <td>Public</td>\n",
       "      <td>Friendly</td>\n",
       "      <td>2017-12-21</td>\n",
       "      <td>2017-12-21</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Columbus First Bancorp Inc</td>\n",
       "      <td>US</td>\n",
       "      <td>Priv.</td>\n",
       "      <td>0H8968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19835 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MASTER_DEAL_NO                      AMANAMES  ACUSIP APUBLIC  ATTITUDE  \\\n",
       "242        411673020  International Remote Imaging  460259  Public  Friendly   \n",
       "287        312002020  Managed Health Benefits Corp  561660  Public  Friendly   \n",
       "379        333750040            MICROS Systems Inc  594901  Public  Friendly   \n",
       "506        360715020      Peer Review Analysis Inc  705478  Public  Friendly   \n",
       "685        381944020           Northern Trust Corp  665859  Public  Friendly   \n",
       "...              ...                           ...     ...     ...       ...   \n",
       "17734     3184713020        American Woodmark Corp  030506  Public  Friendly   \n",
       "17931     3185616040   Westinghouse Air Brake Tech  929740  Public  Friendly   \n",
       "17995     3185792040      Scientific Learning Corp  808760  Public  Friendly   \n",
       "654       3192870020            Verint Systems Inc  92343X  Public  Friendly   \n",
       "2235      3193908020                     LCNB Corp  50181P  Public  Friendly   \n",
       "\n",
       "         DATEANN    DATEEFF    DATEFIN EBITLTM       AMV  ...     PR  \\\n",
       "242   1992-09-30 1995-06-14        NaT     NaN       NaN  ...  19.64   \n",
       "287   1992-12-16 1995-05-19 1993-07-31  -2.323       NaN  ...    NaN   \n",
       "379   1993-05-13 1995-11-30        NaT     NaN       NaN  ...    NaN   \n",
       "506   1993-08-13 1995-03-24 1993-03-31  -2.579    19.682  ...    NaN   \n",
       "685   1993-12-20 1995-03-31        NaT     NaN       NaN  ...    NaN   \n",
       "...          ...        ...        ...     ...       ...  ...    ...   \n",
       "17734 2017-12-01 2017-12-29        NaT     NaN  1510.429  ...    NaN   \n",
       "17931 2017-12-04 2017-12-04 2017-05-31   6.876       NaN  ...    NaN   \n",
       "17995 2017-12-04 2017-12-04        NaT     NaN       NaN  ...    NaN   \n",
       "654   2017-12-19 2017-12-19        NaT     NaN       NaN  ...    NaN   \n",
       "2235  2017-12-21 2017-12-21        NaT     NaN       NaN  ...    NaN   \n",
       "\n",
       "        RANKVAL SALESLTM                      TMANAMES TNATIONCODE TPUBLIC  \\\n",
       "242         3.8      NaN               LDA Systems Inc          US   Priv.   \n",
       "287       8.464    0.684                    Avitar Inc          US  Public   \n",
       "379       28.24      NaN         Fidelio Software GmbH          WG   Priv.   \n",
       "506       7.351    8.122           Core Management Inc          US   Priv.   \n",
       "685        56.2      NaN  Beach One Financial Services          US   Priv.   \n",
       "...         ...      ...                           ...         ...     ...   \n",
       "17734  1080.147      NaN         RSI Home Products Inc          US   Priv.   \n",
       "17931       NaN   36.036                    Melett Ltd          UK   Priv.   \n",
       "17995       NaN      NaN        Brain Maps Tech Co Ltd          CH   Priv.   \n",
       "654        30.0      NaN                  Next It Corp          US   Priv.   \n",
       "2235        NaN      NaN    Columbus First Bancorp Inc          US   Priv.   \n",
       "\n",
       "      MASTER_CUSIP TTICKER agvkey tgvkey  \n",
       "242         50182J     NaN    NaN    NaN  \n",
       "287         053794    AVIT    NaN    NaN  \n",
       "379         31574A     NaN    NaN    NaN  \n",
       "506         21867H     NaN    NaN    NaN  \n",
       "685         07338A     NaN    NaN    NaN  \n",
       "...            ...     ...    ...    ...  \n",
       "17734       74978X     NaN    NaN    NaN  \n",
       "17931       0H3415     NaN    NaN    NaN  \n",
       "17995       0H3486     NaN    NaN    NaN  \n",
       "654         0H8195     NaN    NaN    NaN  \n",
       "2235        0H8968     NaN    NaN    NaN  \n",
       "\n",
       "[19835 rows x 30 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compmna = pd.merge(compmna, sdc_link, left_on='MASTER_DEAL_NO', right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compmna.to_sql('compmna', conn, index=False)\n",
    "sdc_link.to_sql('sdc_link', conn, index=True)\n",
    "\n",
    "qry = '''\n",
    "    select  \n",
    "        compmna.*, sdc_link.agvkey, sdc_link.tgvkey\n",
    "    from\n",
    "        compmna left join sdc_link on\n",
    "        compmna.MASTER_DEAL_NO == sdc_link.DealNumber\n",
    "    '''\n",
    "compmna = pd.read_sql_query(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category variables\n",
    "for col in ['MASTER_DEAL_NO', 'ACUSIP', 'APUBLIC', 'ATTITUDE', 'TNATIONCODE', 'TPUBLIC', 'MASTER_CUSIP']:\n",
    "    compmna[col] = compmna[col].astype('category')\n",
    "\n",
    "var = list(compmna)\n",
    "# floats\n",
    "for col in var[8:23]:\n",
    "    # ENTVAL 'M' Form of Deal is Merger 'P' Deal Status is Partial\n",
    "    compmna[col] = np.where(compmna[col].astype(str).isin(['nan', 'None', 'P', 'M']), np.NaN, compmna[col].astype(str).str.replace(',',''))\n",
    "    compmna[col] = pd.to_numeric(compmna[col]).astype(float)\n",
    "# integers\n",
    "for col in ['agvkey', 'tgvkey']:\n",
    "    compmna[col] = compmna[col].astype('Int64')\n",
    "\n",
    "# date variables\n",
    "for col in ['DATEANN', 'DATEEFF', 'DATEFIN']:\n",
    "    compmna[col] = compmna[col].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link SDC CUSIP and CRSP NCUSIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acusip = compmna[compmna['ACUSIP'].notna()].loc[:,['ACUSIP', 'AMANAMES', 'DATEEFF']].rename(columns={'ACUSIP':'CUSIP', 'AMANAMES':'NAMES'})\n",
    "acusip['TYPE'] = 'A'\n",
    "tcusip = compmna[compmna['MASTER_CUSIP'].notna()].loc[:,['MASTER_CUSIP', 'TMANAMES', 'DATEEFF']].rename(columns={'MASTER_CUSIP':'CUSIP', 'TMANAMES':'NAMES'})\n",
    "tcusip['TYPE'] = 'T'\n",
    "sdc_cusip = acusip.append(tcusip).drop_duplicates(keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Private vs Public \\n', \n",
    "      len(compmna[(compmna['TPUBLIC'] == 'Priv.')]), len(compmna[(compmna['TPUBLIC'] == 'Public')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Public Sales vs N/A \\n', \n",
    "      len(compmna[(compmna['TPUBLIC'] == 'Public') & (compmna['SALESLTM'].notnull())]), \n",
    "      len(compmna[(compmna['TPUBLIC'] == 'Public') & (compmna['SALESLTM'].isna())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Private Sales vs N/A \\n', \n",
    "      len(compmna[(compmna['TPUBLIC'] == 'Priv.') & (compmna['SALESLTM'].notnull())]), \n",
    "      len(compmna[(compmna['TPUBLIC'] == 'Priv.') & (compmna['SALESLTM'].isna())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sdc_cusip.to_csv('/Users/ohn0000/Dropbox/Project/cko/2_pipeline/sdc_cusip.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !scp /Users/ohn0000/Dropbox/Project/cko/2_pipeline/sdc_cusip.csv $WRDS:/scratch/ou/hohn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run '/Users/ohn0000/Dropbox/cko/1_code/cusip.sas' on WRDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !scp /Users/ohn0000/Dropbox/Project/cko/2_pipeline/sdc_cusip.csv $WRDS:~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permno = {'cusip':'category', 'type':'category', 'PERMNO':'category'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdc_permno = pd.read_csv('/Users/ohn0000/Dropbox/Project/cko/2_pipeline/sdc.csv', \n",
    "                         delimiter=',', dtype = permno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdc_permno['dateeff'] = sdc_permno['dateeff'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the db in memory\n",
    "conn = sqlite3.connect(':memory:')\n",
    "# write the tables\n",
    "compmna.to_sql('compmna', conn, index=False)\n",
    "sdc_permno.drop_duplicates(['cusip','dateeff']).to_sql('sdc_permno', conn, index=False)\n",
    "\n",
    "qry = '''\n",
    "    select  \n",
    "        compmna.*, a.PERMNO as apermno, b.permno as tpermno\n",
    "    from\n",
    "        compmna left join sdc_permno a on\n",
    "        compmna.acusip == a.cusip and compmna.DATEEFF == a.dateeff\n",
    "        left join sdc_permno b on\n",
    "        compmna.MASTER_CUSIP == b.cusip and compmna.DATEEFF == b.dateeff\n",
    "    '''\n",
    "compmna = pd.read_sql_query(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the db in memory\n",
    "conn = sqlite3.connect(':memory:')\n",
    "# write the tables\n",
    "compmna[(compmna['apermno'].isna()) | (compmna['tpermno'].isna())].to_sql(\n",
    "    'compmna', conn, index=False)\n",
    "sdc_permno[sdc_permno['PERMNO'].notnull()].to_sql('sdc_permno', conn, index=False)\n",
    "\n",
    "qry = '''\n",
    "    select  \n",
    "        compmna.ACUSIP, compmna.DATEEFF, a.PERMNO as apermno1, b.permno as tpermno1\n",
    "    from\n",
    "        compmna left join sdc_permno a on\n",
    "        compmna.acusip == a.cusip\n",
    "        left join sdc_permno b on\n",
    "        compmna.MASTER_CUSIP == b.cusip\n",
    "    '''\n",
    "aug_compmna = pd.read_sql_query(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_compmna.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compmna.to_sql('compmna', conn, index = False, if_exists='replace')\n",
    "aug_compmna.to_sql('aug', conn, index = False, if_exists='replace')\n",
    "qry = '''\n",
    "    select\n",
    "        compmna.*, aug.apermno1, aug.tpermno1\n",
    "    from \n",
    "        compmna left join aug on\n",
    "        compmna.acusip = aug.acusip and compmna.dateeff = aug.dateeff\n",
    "'''\n",
    "compmna = pd.read_sql_query(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compmna['apermno'] = np.where((compmna['apermno'].isna()) & (compmna['apermno1'].notnull()), \n",
    "                              compmna['apermno1'], compmna['apermno'])\n",
    "compmna['tpermno'] = np.where((compmna['tpermno'].isna()) & (compmna['tpermno1'].notnull()), \n",
    "                              compmna['tpermno1'], compmna['tpermno'])\n",
    "compmna.drop(columns = ['apermno1', 'tpermno1'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compmna.drop_duplicates('MASTER_DEAL_NO', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierarchy for gvkey\n",
    "1. EPW Linkfile \n",
    "2. Permno + M&A effective date\n",
    "3. Permno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the tables\n",
    "compmna.to_sql('compmna', conn, index=False, if_exists='replace')\n",
    "linktable.to_sql('linktable', conn, index = False, if_exists='replace')\n",
    "qry = '''\n",
    "    select  \n",
    "        compmna.*, a.gvkey as agvkey1, b.gvkey as tgvkey1\n",
    "    from\n",
    "        compmna left join linktable a on\n",
    "        compmna.apermno == a.permno and compmna.dateeff between a.linkdt and a.linkenddt\n",
    "        left join linktable b on\n",
    "        compmna.tpermno == b.permno and compmna.dateeff between b.linkdt and b.linkenddt\n",
    "    '''\n",
    "compmna_temp1 = pd.read_sql_query(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compmna_temp1.to_sql('compmna', conn, index=False, if_exists='replace')\n",
    "linktable.to_sql('linktable', conn, index = False, if_exists='replace')\n",
    "qry = '''\n",
    "    select  \n",
    "        compmna.*, a.gvkey as agvkey2, b.gvkey as tgvkey2\n",
    "    from\n",
    "        compmna left join linktable a on\n",
    "        compmna.apermno == a.permno\n",
    "        left join linktable b on\n",
    "        compmna.tpermno == b.permno\n",
    "    '''\n",
    "compmna_temp2 = pd.read_sql_query(qry, conn)\n",
    "\n",
    "condlist = [compmna_temp2['agvkey'].notnull(), \n",
    "            (compmna_temp2['agvkey'].isna()) & (compmna_temp2['agvkey1'].notnull()),\n",
    "            (compmna_temp2['agvkey'].isna()) & (compmna_temp2['agvkey1'].isna()) & \n",
    "            (compmna_temp2['agvkey2'].notnull()),\n",
    "            (compmna_temp2['agvkey'].isna()) & (compmna_temp2['agvkey1'].isna()) & \n",
    "            (compmna_temp2['agvkey2'].isna())\n",
    "           ]\n",
    "choicelist = [compmna_temp2['agvkey'],compmna_temp2['agvkey1'], compmna_temp2['agvkey2'], np.NaN]\n",
    "\n",
    "compmna_temp2['agvkey'] = np.select(condlist, choicelist)\n",
    "\n",
    "condlist = [compmna_temp2['tgvkey'].notnull(), \n",
    "            (compmna_temp2['tgvkey'].isna()) & (compmna_temp2['tgvkey1'].notnull()),\n",
    "            (compmna_temp2['tgvkey'].isna()) & (compmna_temp2['tgvkey1'].isna()) & \n",
    "            (compmna_temp2['tgvkey2'].notnull()),\n",
    "            (compmna_temp2['tgvkey'].isna()) & (compmna_temp2['tgvkey1'].isna()) & \n",
    "            (compmna_temp2['tgvkey2'].isna())\n",
    "           ]\n",
    "choicelist = [compmna_temp2['tgvkey'],compmna_temp2['tgvkey1'], compmna_temp2['tgvkey2'], np.NaN]\n",
    "\n",
    "compmna_temp2['tgvkey'] = np.select(condlist, choicelist)\n",
    "\n",
    "compmna_temp2.drop(columns=['agvkey1', 'agvkey2', 'tgvkey1', 'tgvkey2'], inplace=True)\n",
    "\n",
    "for var in ['agvkey', 'tgvkey']:\n",
    "    compmna_temp2[var] = compmna_temp2[var].astype('Int64')\n",
    "    compmna_temp2[var] = compmna_temp2[var].astype('category')\n",
    "for var in ['apermno', 'tpermno']:\n",
    "    compmna_temp2[var] = compmna_temp2[var].astype('category')\n",
    "\n",
    "compmna_temp2[[\"agvkey\", \"tgvkey\", \"apermno\", \"tpermno\"]] = compmna_temp2[[\"agvkey\", \"tgvkey\", \"apermno\", \"tpermno\"]].fillna(\n",
    "        compmna_temp2.groupby(['MASTER_DEAL_NO'])[[\"agvkey\", \"tgvkey\", \"apermno\", \"tpermno\"]].ffill())\n",
    "\n",
    "compmna_temp2.drop_duplicates('MASTER_DEAL_NO', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compmna = compmna_temp2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of SDC observations with non-missign acquirer's _gvkey_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(compmna[compmna['agvkey'].notnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadate['lagdate'] = datadate.groupby('gvkey1')['datadate'].shift(1) + pd.DateOffset(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadate['lagdate'] = np.where(datadate['lagdate'].isna(),\n",
    "                              datadate['datadate'] - pd.DateOffset(years=1) + pd.DateOffset(days=1),\n",
    "                              datadate['lagdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadate[datadate['lagdate'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compmna['DATEEFF'] = compmna['DATEEFF'].astype('datetime64[ns]')\n",
    "compmna.to_sql('compmna', conn, index=False, if_exists='replace')\n",
    "datadate.to_sql('datadate', conn, index = True, if_exists='replace')\n",
    "qry = '''\n",
    "    select *\n",
    "    from \n",
    "        (select\n",
    "                a.*, b.datadate, b.fyear\n",
    "            from\n",
    "                compmna a left join datadate b on\n",
    "                a.agvkey == b.gvkey1 and b.datadate >= a.dateeff\n",
    "            group by \n",
    "                a.MASTER_DEAL_NO\n",
    "        )\n",
    "        '''\n",
    "temp1 = pd.read_sql_query(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1['datedif'] = (pd.to_datetime(temp1['datadate']) - pd.to_datetime(temp1['DATEEFF'])).dt.days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compmna = temp1[temp1['datedif'] <= 370].drop(columns='datedif')\n",
    "\n",
    "col = list(compmna)\n",
    "col.insert(5, col.pop(col.index('datadate')))\n",
    "col.insert(6, col.pop(col.index('fyear')))\n",
    "compmna = compmna[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category variables\n",
    "for col in ['MASTER_DEAL_NO', 'ACUSIP', 'APUBLIC', 'ATTITUDE', 'TNATIONCODE', 'TPUBLIC', 'MASTER_CUSIP']:\n",
    "    compmna[col] = compmna[col].astype('category')\n",
    "\n",
    "var = list(compmna)\n",
    "\n",
    "# integers\n",
    "for col in ['fyear', 'agvkey', 'tgvkey', 'apermno', 'tpermno']:\n",
    "    compmna[col] = pd.to_numeric(compmna[col], downcast='integer').astype('Int64')\n",
    "    compmna[col] = compmna[col].astype('category')\n",
    "\n",
    "# date variables\n",
    "for col in ['datadate', 'DATEANN', 'DATEEFF', 'DATEFIN']:\n",
    "    compmna[col] = compmna[col].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compmna.set_index('MASTER_DEAL_NO', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SDC obsevations with logical (less than 400 day difference from effective date) Compustat _datadate_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(compmna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(compmna[compmna['RANKVAL'].notnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(compmna[compmna['SALESLTM'].notnull()]), '\\n',\n",
    "      len(compmna[(compmna['SALESLTM'].isna()) & (compmna['tgvkey'].notnull())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(compmna[(compmna['AMV'].notnull())]), '\\n',\n",
    "      len(compmna[(compmna['AMV'].isna()) & (compmna['apermno'].notnull())]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct IV by acquirer's _gvkey_ and _datadate_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab acquirers' lag sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sales = compmna[(compmna['agvkey'].notnull()) | \n",
    "                    (compmna['tgvkey'].notnull())][['agvkey', 'tgvkey', 'fyear']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_query = \"\"\"\n",
    "select distinct gvkey, datadate, fyear, sale\n",
    "from comp.funda\n",
    "where consol = %(consol)s and indfmt in %(indfmt)s \n",
    "    and datafmt = %(datafmt)s and popsrc = %(popsrc)s\n",
    "    and curcd in %(curcd)s and sale is not null\n",
    "order by gvkey, fyear\n",
    "\"\"\"\n",
    "\n",
    "parm = {'consol':('C'), 'indfmt' : ('INDL', 'FS'), 'datafmt': ('STD'), 'popsrc' : ('D'), 'curcd' : ('USD', 'CAD')}\n",
    "sale = db.raw_sql(comp_query, date_cols=['datadate'], params=parm)\n",
    "\n",
    "sale['fyear'] = sale['fyear'].astype('int16')\n",
    "sale['gvkey'] = pd.to_numeric(sale['gvkey']).astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sale.drop_duplicates(['gvkey','fyear'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sale[sale['gvkey']==112626]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sale['fyear1'] = sale['fyear'] - 1\n",
    "lagset = sale[['gvkey', 'fyear', 'sale']].copy()\n",
    "lagset.rename(columns={'fyear': 'fyear1', 'sale':'l_sale'}, inplace=True)\n",
    "sale = pd.merge(sale, lagset, on=['gvkey','fyear1'], how='left')\n",
    "\n",
    "sale.drop(columns=['fyear1'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = list(get_sales)\n",
    "col = col + ['a_sale']\n",
    "get_sales = get_sales.merge(sale, \n",
    "                            left_on=['agvkey', 'fyear'], right_on=['gvkey', 'fyear'], \n",
    "                            how='left').rename(columns={'l_sale':'a_sale'})\n",
    "\n",
    "get_sales = get_sales[col]\n",
    "col = col + ['t_sale']\n",
    "get_sales = get_sales.merge(sale, \n",
    "                            left_on=['tgvkey', 'fyear'], right_on=['gvkey', 'fyear'], \n",
    "                            how='left').rename(columns={'l_sale':'t_sale'})\n",
    "get_sales = get_sales[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sales['tgvkey'] = np.where(get_sales['tgvkey'] < 0, np.NaN, get_sales['tgvkey'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sales[get_sales['a_sale'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "compmna[compmna['agvkey'] == 112626]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Private Target Data (Chen 2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _encoding_ option allows proper string imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw = pd.read_sas('../0_data/manual/CW2019.sas7bdat', format = 'sas7bdat', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw['gvkey1'] = pd.to_numeric(cw['gvkey']).astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_priv_ dataset is a subset of _compmna_ that will be matched to Ciao-Wei's data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priv = sdc[(sdc['RANKVAL'].notnull()) & (sdc['TPUBLIC'] == 'Priv.')]\n",
    "priv.drop_duplicates(inplace=True)\n",
    "priv = priv[(priv['DATEEFF'] >= '1997-01-01') & (priv['DATEEFF'] <= '2013-12-31')]\n",
    "private = priv.compute()\n",
    "\n",
    "for var in ['DATEANN', 'DATEEFF']:\n",
    "    private[var] = pd.to_datetime(private[var]).astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below grabs all but 5 _MASTER_DEAL_NO_ from _private_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge by dates and names\n",
    "cw = cw.merge(private[['AMANAMES', 'DATEANN', 'DATEEFF', 'TMANAMES', 'MASTER_DEAL_NO']],\n",
    "         left_on=['ACQ_NAME', 'ANN', 'EFF', 'TRG_NAME'],\n",
    "         right_on=['AMANAMES', 'DATEANN', 'DATEEFF', 'TMANAMES'], how='left')\n",
    "col = list(cw)\n",
    "col.insert(0, col.pop())\n",
    "cw = cw[col]\n",
    "\n",
    "cw.drop(columns=['AMANAMES', 'DATEANN', 'DATEEFF', 'TMANAMES'], inplace=True)\n",
    "\n",
    "cw.drop_duplicates(inplace=True)\n",
    "\n",
    "# review dates and names of the missing\n",
    "missing = private[['MASTER_DEAL_NO', 'AMANAMES', 'DATEANN', 'DATEEFF', 'TMANAMES']].merge(cw[cw['MASTER_DEAL_NO'].isna()][['ANN', 'EFF', 'ACQ_NAME', 'TRG_NAME']],\n",
    "                                                           how='right',left_on=['DATEANN', 'DATEEFF'], right_on=['ANN', 'EFF'])\n",
    "\n",
    "missing.drop_duplicates(inplace=True)\n",
    "missing.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# manual match\n",
    "missing = missing.iloc[[0, 1, 5, 16, 24, 26, 28, 29, 39, 44, 53]][['MASTER_DEAL_NO', 'ANN', 'EFF', 'ACQ_NAME', 'TRG_NAME']]\n",
    "\n",
    "# update MASTER_DEAL_NO\n",
    "cw = cw.merge(missing, \n",
    "         left_on=['ACQ_NAME', 'ANN', 'EFF', 'TRG_NAME'],\n",
    "         right_on=['ACQ_NAME', 'ANN', 'EFF', 'TRG_NAME'], how='left', suffixes=('','_y'))\n",
    "\n",
    "cw['MASTER_DEAL_NO'] = np.where(cw['MASTER_DEAL_NO'].isna(), cw['MASTER_DEAL_NO_y'], cw['MASTER_DEAL_NO'])\n",
    "\n",
    "cw.drop(columns=['MASTER_DEAL_NO_y'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = list(cw)\n",
    "col.insert(1, col.pop())\n",
    "cw = cw[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw.to_sql('compmna', conn, index=False, if_exists='replace')\n",
    "datadate.to_sql('datadate', conn, index = True, if_exists='replace')\n",
    "qry = '''\n",
    "    select  \n",
    "        a.*, b.datadate\n",
    "    from\n",
    "        compmna a join datadate b on\n",
    "        a.gvkey1 == b.gvkey1 and a.EFF between b.lagdate and b.datadate \n",
    "    '''\n",
    "cw = pd.read_sql_query(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw['datadate'] = pd.to_datetime(cw['datadate']).astype('datetime64[ns]')\n",
    "\n",
    "cw['year'] = cw['datadate'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql('avg_sim', conn, index=False, if_exists='replace')\n",
    "cw.to_sql('cw', conn, index = False, if_exists='replace')\n",
    "qry = '''\n",
    "    select  \n",
    "        a.*\n",
    "    from\n",
    "        avg_sim a join (select distinct gvkey1, year from cw) b\n",
    "        on a.gvkey1 = b.gvkey1 and a.year = b.year\n",
    "    '''\n",
    "cw_sim = pd.read_sql_query(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_sim = cw_sim[['gvkey1', 'year', 'dt_s1', 'dt_z1', 'dt_s2', 'dt_z2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnic_industry.to_sql('tnic', conn, index=True, if_exists='replace')\n",
    "cw_sim.to_sql('cw_sim', conn, index = False, if_exists='replace')\n",
    "qry = '''\n",
    "    select  \n",
    "        a.gvkey1, a.year, a.gvkey2\n",
    "    from\n",
    "        tnic a join (select distinct gvkey1, year from cw_sim) b\n",
    "        on a.gvkey1 = b.gvkey1 and a.year = b.year\n",
    "    '''\n",
    "cw_tnic = pd.read_sql_query(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_tnic = cw_tnic.merge(df[['gvkey1', 'year', 'dt_s1', 'dt_s2', 'dt_z1', 'dt_z2']]\n",
    "                        , left_on=['gvkey2', 'year'], right_on=['gvkey1', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_tnic.drop(columns=['gvkey1_y'], inplace=True)\n",
    "cw_tnic.rename(columns={'gvkey1_x':'gvkey1'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnic_avg = cw_tnic.groupby(['gvkey1', 'year']).mean().drop(columns=['gvkey2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_sim = cw_sim.merge(tnic_avg, left_on=['gvkey1', 'year'], right_on=['gvkey1', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_sim['dt_s1'] = cw_sim['dt_s1_x'] - cw_sim['dt_s1_y']\n",
    "cw_sim['dt_z1'] = cw_sim['dt_z1_x'] - cw_sim['dt_z1_y']\n",
    "cw_sim['dt_s2'] = cw_sim['dt_s2_x'] - cw_sim['dt_s2_y']\n",
    "cw_sim['dt_z2'] = cw_sim['dt_z2_x'] - cw_sim['dt_z2_y'] \n",
    "# cw_sim = cw_sim[['gvkey1', 'year', 'dt_s1', 'dt_z1', 'dt_s2', 'dt_z2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw = cw.merge(cw_sim, left_on=['gvkey1', 'year'], right_on=['gvkey1', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw.to_stata('/Users/ohn0000/Dropbox/Project/cko/2_pipeline/cw.dta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Materiality of M&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "material = pd.read_csv('/Users/ohn0000/Project/cko/0_data/external/materiality.csv')\n",
    "material.set_index([\"year\", \"gvkey1\"], inplace=True, verify_integrity=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful since the _year_ here refers to the M&A firm-year. The _year_ in __avg_sim__ is the year competitors are identified. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M&A Disclosure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = pd.read_csv('/Users/ohn0000/Project/cko/0_data/manual/disc.csv', parse_dates=['DATADATE'])\n",
    "disc['CIK'] = disc['CIK'].apply(lambda x: str(int(x)).zfill(10) if pd.notnull(x) else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disclosure also might need additonal data collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc.rename(columns={\"GVKEY\":\"gvkey1\", \"FYEAR\":\"year\"}, inplace=True)\n",
    "disc.set_index([\"year\", \"gvkey1\"], inplace=True, verify_integrity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual = disc.join(material)[['DATADATE', 'CIK', 'TGTAT_ACQAT', 'TGTDVAL_ACQAT', 'MD_A', 'PROFORMA']].sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wrds\n",
    "db = wrds.Connection(wrds_username = \"yaera\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_details_desc = db.describe_table('sdc', 'ma_details').sort_values('name')\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    print(ma_details_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|     Variable | Description                    |\n",
    "|:------------:|:-------------------------------|\n",
    "|bookvalue     |Target Book Value (\\$mil)       |\n",
    "|compete       |Competing Bidder (Y/N)          |\n",
    "|competecode   |Competing Bid Deal Code         |  \n",
    "|dateann       |Date Announced                  |\n",
    "|dateannest    |_dateann_ is estimated (Y/N)    | \n",
    "|dateeff       |Date Effective                  | \n",
    "|ebitltm       |Target EBIT LTM (\\$mil)         |\n",
    "|pct_cash      |Percentage of consideration paid in cash|\n",
    "|pct_other|Percentage of consideration paid in other then cash or stock|\n",
    "|pct_stk|Percentage of consideration paid in stock|\n",
    "|pct_unknown|Percentage of consideration which is unknown|\n",
    "|ptincltm|Target Pre-Tax Income LTM (\\$mil)|\n",
    "|salesltm|Target Sales LTM (\\$mil)|\n",
    "|rankval|Ranking Value incl Net Debt of Target (\\$mil)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run sql query below on _WRDS_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wrds\n",
    "# sdc_query = \"\"\"\n",
    "# select master_deal_no as DealNumber, \n",
    "#         bookvalue, \n",
    "#         compete, \n",
    "#         competecode, \n",
    "#         dateann, \n",
    "#         dateannest, \n",
    "#         dateeff, \n",
    "#         ebitltm, \n",
    "#         pct_cash,\n",
    "#         pct_other,\n",
    "#         pct_stk,\n",
    "#         pct_unknown,\n",
    "#         ptincltm,\n",
    "#         salesltm,\n",
    "#         rankval\n",
    "# from sdc.ma_details\n",
    "# where dateeff is not null \n",
    "# \"\"\"\n",
    "# # and master_deal_no in %(deal_no)s\n",
    "# sdc = db.raw_sql(sdc_query, date_cols=['dateann', 'dateeff'])\n",
    "# sdc.to_pickle('/home/upenn/yaera/sdc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdc = pd.read_pickle('/Users/ohn0000/Project/cko/0_data/external/sdc.pkl')\n",
    "sdc.drop_duplicates('dealnumber', inplace = True)\n",
    "sdc['dealnumber'] = sdc['dealnumber'].astype('int64')\n",
    "\n",
    "# clear up values and change dtype to 'float'\n",
    "for column in ['bookvalue', 'ebitltm', 'pct_cash', 'pct_other', 'pct_stk', 'pct_unknown', 'ptincltm', 'salesltm', 'rankval']:\n",
    "    sdc[column] = sdc[column].apply(lambda x: np.NaN if x == '*********' else (np.NaN if pd.isna(x) else (float(x.replace(',', '')) if isinstance(x, str) else float(x))))\n",
    "    sdc[column].astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdc_sub = pd.merge(sdc_link, sdc,\n",
    "                   left_index=True, right_on='dealnumber').drop('dealnumber', axis='columns')\n",
    "sdc_sub.index.name = 'dealnumber'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdc_sub.sort_values(['agvkey', 'dateeff'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdc_link['agvkey'].count() / sdc['dealnumber'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdc_sub['agvkey'].count() / sdc_link['agvkey'].count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdc_sub.profile_report(style={'full_width':True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use __compustat__ _datadate_ and gvkey to link the sdc data to the similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wrds\n",
    "db = wrds.Connection(wrds_username = 'hohn')\n",
    "\n",
    "sdc_quary = \"\"\"\n",
    "select gvkey, datadate, fyear, cusip,  cik\n",
    "from comp.funda\n",
    "where consol = %(consol)s and indfmt in %(indfmt)s and datafmt = %(datafmt)s and popsrc = %(popsrc)s and curcd in %(curcd)s\n",
    "\"\"\"\n",
    "\n",
    "parm = {'consol':('C'), 'indfmt' : ('INDL', 'FS'), 'datafmt': ('STD'), 'popsrc' : ('D'), 'curcd' : ('USD', 'CAD')}\n",
    "\n",
    "funda = db.raw_sql(sdc_quary, params = parm, date_cols = ['datadate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funda['start'] = funda['datadate'] - pd.DateOffset(months = 12) + pd.DateOffset(days = 1)\n",
    "funda['gvkey'] = funda['gvkey'].astype('int64')\n",
    "funda.set_index('gvkey', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funda.fyear = funda.fyear.astype('Int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandasql as ps\n",
    "\n",
    "sql_query = '''\n",
    "select a.*, b.datadate, b.fyear, b.cusip, b.cik\n",
    "from sdc_sub a left join funda b\n",
    "on a.agvkey = b.gvkey and a.dateeff between b.start and b.datadate\n",
    "'''\n",
    "\n",
    "newdf = ps.sqldf(sql_query, locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = list(newdf)\n",
    "for i in range(2, 6):\n",
    "    col.insert(i, col.pop(-1))\n",
    "newdf = newdf.loc[:,col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['datadate', 'dateann', 'dateeff']:\n",
    "    newdf[i] = newdf[i].astype('datetime64[ns]')\n",
    "    \n",
    "newdf['year'] = newdf['datadate'].dt.year.astype('Int16')\n",
    "for i in ['fyear', 'agvkey', 'tgvkey']:\n",
    "    newdf[i] = newdf[i].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = list(newdf)\n",
    "col.insert(col.index('datadate'), col.pop(col.index('year')))\n",
    "newdf = newdf.loc[:,col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = newdf.drop_duplicates(subset='dealnumber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf[newdf['agvkey'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf['rankval'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18994 observations with non-missing _rankval_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf['salesltm'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8055 observations with non-missing _salesltm_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(newdf['rankval'].notnull() & newdf['salesltm'].notnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6445 observations with both _rankval_ and _salesltm_ available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append similarity score between acquirer and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload = newdf[newdf['agvkey'].notnull() & newdf['tgvkey'].notnull() & newdf['year'].notnull()][['agvkey', 'tgvkey', 'year']].rename(columns={'agvkey':'gvkey1', 'tgvkey':'gvkey2'})\n",
    "upload.to_csv('/Users/ohn0000/Project/cko/2_pipeline/upload.csv', index=False)\n",
    "!scp /Users/ohn0000/Project/cko/2_pipeline/upload.csv $WRDS:/scratch/ou/hohn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this on wrds server. The __TNIC_All__ files should be uploaded in scratch beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The server killed the previous code that joins after combines all files. The current code instead loop over the files.\n",
    "\"\"\"\n",
    "# !cd /scratch/ou/hohn/TNIC_AllPairsDistrib\n",
    "# !cat tnicall1996.txt > tnicall_combined.txt\n",
    "# !for file in tnicall{1997..2017}.txt; do sed '1d' $file >> tnicall_combined.txt; done\n",
    "# !cd ~\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "atsim.py\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scp atsim.py $WRDS:~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scp $WRDS:/scratch/ou/hohn/atsim.csv /Users/ohn0000/Project/cko/2_pipeline/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = list(newdf)\n",
    "col.insert(col.index('bookvalue'), col.pop(col.index('atsim')))\n",
    "newdf = newdf.loc[:,col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV candidates\n",
    "\n",
    "The materiality measure based on deal value will be the last resort for the IV.   \n",
    "Alternatively, 2SLS using multiple IVs is feasible.\n",
    "\n",
    "Candidates\n",
    "* Max deal value\n",
    "* Sum deal value\n",
    "* Datedif between _dateeff_ and _datadate_\n",
    "    * _dateeff_ of the first M&A\n",
    "    * _dateeff_ of the largest M&A\n",
    "    * weighted average of _dateeff_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-sections\n",
    "* Similarity between acquirer and target \n",
    "    - Relation stronger in diversifying\n",
    "    - Could be more of a U-shaped relation, i.e., competitors don't follow when you move far enough\n",
    "* Average value of pre-similarities between acquirer and close competitors \n",
    "    - Prediction not clear\n",
    "* M&A performance during the completed firm-year\n",
    "    - Relation stronger when M&A was more successful <-> how do we define success of an M&A?\n",
    "* Number of close competitors of the target\n",
    "    - Potential targets are candidates of future mergers\n",
    "* How many competitors were there initially?\n",
    "    - The size of the TNIC industry"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "450px",
    "left": "1518px",
    "right": "20px",
    "top": "120px",
    "width": "382px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
