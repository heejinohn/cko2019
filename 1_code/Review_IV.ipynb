{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CKO JAR Revision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rpy2.rinterface #ggplot tool\n",
    "from pandas_profiling import ProfileReport\n",
    "import dask.dataframe as dd\n",
    "import wrds\n",
    "import pandasql as ps\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Review TNIC-3 data\n",
    "\n",
    "# ### Import TNIC3 data from Hoberg and Philips data library \n",
    "\n",
    "# # !wget -P ../2_pipeline/ http://hobergphillips.tuck.dartmouth.edu/idata/tnic3_data.zip\n",
    "# # !unzip -q ../2_pipeline/tnic3_data.zip -d ../2_pipeline/ && rm ../2_pipeline/tnic3_data.zip\n",
    "\n",
    "# \"\"\"\n",
    "# Hoberg and Philips TNIC3 database\n",
    "# \"\"\"\n",
    "# tnic = pd.read_csv('/Users/ohn0000/Dropbox/Project/cko/0_data/external/tnic3_data.txt', \n",
    "#                    delimiter='\\t', header=0, index_col=['gvkey1', 'year', 'gvkey2'])\n",
    "# tnic.dropna(inplace=True)\n",
    "\n",
    "# ### Subset to 20-closest competitors\n",
    "\n",
    "# # tnic_industry = tnic.groupby(level=['gvkey1', 'year'])[\"score\"].nlargest(20).reset_index(level=[0,1], drop=True)\n",
    "# # tnic_industry = tnic_industry.to_frame(name='score')\n",
    "# # tnic_industry.to_pickle('../2_pipeline/tnic_industry.pkl')\n",
    "# tnic_industry = pd.read_pickle('../2_pipeline/tnic_industry.pkl')\n",
    "\n",
    "# ```tnic_industry``` still has firm-years with less than 20 competitors.\n",
    "\n",
    "# # \"\"\"\n",
    "# # Require at least 20 closest competitors\n",
    "# # \"\"\"\n",
    "# # tnicind_sub = tnic.groupby(level=['gvkey1', 'year'])[\"score\"].filter(lambda x: x.size == 20)\n",
    "# # tnicind_sub = tnicind_sub.to_frame(name='score')\n",
    "\n",
    "# \"\"\"\n",
    "# tnic_industry['gvkey1'] = tnic_industry['gvkey1'].apply(lambda x: str(x).zfill(6))\n",
    "# tnic_industry['gvkey2'] = tnic_industry['gvkey2'].apply(lambda x: str(x).zfill(6))\n",
    "# \"\"\"\n",
    "\n",
    "# Remeber that _year_ in __tnic_industry__ is the base year for identifying close competitors. Accordingly, _lead1_ is the M&A year and _lead2_ is the year following M&A.\n",
    "\n",
    "# Readme_tnic3.txt explains that _year_ equals the first four digits of the __compustat__ _datadate_.\n",
    "\n",
    "# ### Shift years in __tnic_industry__ to get _lead1_ and _lead2_ similarity scores\n",
    "\n",
    "# tnic_industry.rename(columns={'score':'score_0'}, inplace=True)\n",
    "\n",
    "# for i in range(1,3):\n",
    "#     colname = 'score' + '_' + str(i)\n",
    "#     tnic_industry['score'] = np.NaN\n",
    "#     tnic_industry.index = tnic_industry.index.set_levels(tnic_industry.index.levels[1] + 1, level=1)\n",
    "#     tnic_industry.update(tnic)\n",
    "#     tnic_industry.rename(columns={'score':colname}, inplace=True)\n",
    "\n",
    "# tnic_industry.reset_index(inplace=True)\n",
    "# tnic_industry[\"year\"] -= 2\n",
    "# tnic_industry.set_index([\"gvkey1\", \"year\", \"gvkey2\"], inplace=True)\n",
    "\n",
    "# tnic_industry.to_pickle('../2_pipeline/tnic_industry.pkl')\n",
    "\n",
    "# ### Run __*tnic_industry.py*__ on _WRDS_ to update lead scores\n",
    "\n",
    "# Many of the _lead1_ and _lead2_ values are missing. Grab these values from __TNIC_Advanced__ uploaded on _WRDS_. \n",
    "\n",
    "# # !scp ../2_pipeline/tnic_industry.pkl tnic_industry.py $WRDS:~\n",
    "\n",
    "# ### Download updated __*tnic_industry*__ file from WRDS\n",
    "\n",
    "# # !scp $WRDS:/scratch/ou/hohn/tnic_ind_update.pkl ../2_pipeline/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnic_industry = pd.read_pickle('../2_pipeline/tnic_ind_update.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average TNIC similarity score across 20-closest competitors.  \n",
    "Remeber that in __TNIC_ALL__ most of the scores equals to zero. The _z\\__ might be the more suitable.\n",
    "- Close pair in t0 not appearing in t1 or t2 is meaningful.\n",
    "- __BE CAREFUL__ of year 2016 and 2017. __TNIC is available only up to 2017__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sim = tnic_industry.groupby(level=['gvkey1','year']).mean()\n",
    "avg_sim = avg_sim.join(tnic_industry.groupby(level=['gvkey1','year']).count().add_prefix(\"n_\"))\n",
    "avg_sim = avg_sim.join(tnic_industry.fillna(0).groupby(level=['gvkey1','year']).mean().add_prefix(\"z_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109791"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(avg_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab COMPUSTAT _datadate_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revise here if _avg\\_sim_ needs additional COMPUSTAT variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading library list...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "db = wrds.Connection(wrds_username='yaera')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_query = \"\"\"\n",
    "select distinct gvkey, datadate, fyear, indfmt, sale\n",
    "from comp.funda\n",
    "where consol = %(consol)s and indfmt in %(indfmt)s \n",
    "    and datafmt = %(datafmt)s and popsrc = %(popsrc)s\n",
    "    and curcd in %(curcd)s\n",
    "order by gvkey, fyear\n",
    "\"\"\"\n",
    "\n",
    "parm = {'consol':('C'), 'indfmt' : ('INDL', 'FS'), 'datafmt': ('STD'), 'popsrc' : ('D'), 'curcd' : ('USD', 'CAD')}\n",
    "comp = db.raw_sql(comp_query, date_cols=['datadate'], params=parm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp['fyear'] = comp['fyear'].astype('int16')\n",
    "comp['year'] = comp['datadate'].dt.year.astype('int16')\n",
    "\n",
    "comp['gvkey1'] = pd.to_numeric(comp['gvkey']).astype('int64')\n",
    "comp.drop(columns='gvkey', inplace=True)\n",
    "\n",
    "comp.set_index(['gvkey1', 'fyear'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not sure how TNIC deals fiscal years where fyear are differenct but\n",
    "year are the same. Assume the lastest datadate within _year_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadate = comp[~comp.index.duplicated(keep='last')][['datadate', 'year']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sim = pd.merge(avg_sim, datadate, \n",
    "                 left_index=True, \n",
    "                 right_on=['gvkey1', 'year'], how='left').drop_duplicates(['gvkey1', 'year'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sim = avg_sim[avg_sim['datadate'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TNIC data not missing _datadate_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109757"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(avg_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = list(avg_sim)\n",
    "col = col[-4:] + col[:-4]\n",
    "avg_sim = avg_sim[col].sort_values(['gvkey1', 'year', 'datadate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab _permno_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revise here if _avg\\_sim_ needs additional CRSP variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query= \"\"\"\n",
    "select gvkey, liid as iid, lpermno as permno, linkdt, linkenddt\n",
    "from crsp.ccmxpf_linktable\n",
    "where linktype in %(type)s and linkprim in %(prim)s and usedflag = 1\n",
    "\"\"\"\n",
    "\n",
    "parm = {'type':('LU', 'LC'), 'prim':('P', 'C')}\n",
    "linktable = db.raw_sql(sql_query, date_cols=['linkdt', 'linkenddt'], params=parm)\n",
    "\n",
    "linktable['gvkey'] = pd.to_numeric(linktable['gvkey'])\n",
    "linktable['permno'] = pd.to_numeric(linktable['permno']).astype('int64')\n",
    "linktable['iid'] = linktable['iid'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "enddt = pd.to_datetime('2020-01-07 00:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "linktable['linkenddt'] = linktable['linkenddt'].fillna(value = enddt)\n",
    "linktable['linkenddt'] = linktable['linkenddt'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(':memory:')\n",
    "avg_sim.to_sql('avg_sim', conn, index=False)\n",
    "linktable.to_sql('linktable', conn, index=False)\n",
    "\n",
    "qry = '''\n",
    "    select  \n",
    "        avg_sim.*, linktable.permno\n",
    "    from\n",
    "        avg_sim left join linktable on\n",
    "        avg_sim.datadate between linkdt and linkenddt and avg_sim.gvkey1 = linktable.gvkey\n",
    "    '''\n",
    "df = pd.read_sql_query(qry, conn)\n",
    "df['permno'] = df['permno'].astype('Int64')\n",
    "df['datadate'] = df['datadate'].astype('datetime64[ns]')\n",
    "\n",
    "df[df['permno'].isna()].to_sql('df', conn, index=False)\n",
    "\n",
    "qry = '''\n",
    "    select\n",
    "        a.*, b.gvkey1, b.datadate\n",
    "        from linktable a join df b\n",
    "        on \n",
    "            a.gvkey = b.gvkey1\n",
    "'''\n",
    "aug = pd.read_sql_query(qry, conn)\n",
    "\n",
    "aug.to_sql('aug', conn, index=False)\n",
    "qry = '''\n",
    "    select gvkey1, permno, iid, min(linkdt) as linkdt, max(linkenddt) as linkenddt\n",
    "    from aug\n",
    "    group by gvkey1, permno, iid\n",
    "    order by gvkey1, linkdt\n",
    "'''\n",
    "\n",
    "df = df.merge(aug[aug['iid'].isin(['01','02'])].rename(columns={'permno':'permno1'})[['gvkey1', 'permno1']], \n",
    "         left_on = ['gvkey1'], right_on=['gvkey1'], how='left')\n",
    "df['permno'] = np.where(df['permno'].isna(), df['permno1'], df['permno'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(['gvkey1', 'year']).drop(columns='permno1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = list(df)\n",
    "col.insert(2, col.pop(col.index('permno')))\n",
    "df = df[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dt_s1'] = np.where(df['year'] == 2017, np.NaN, df['score_1'] - df['score_0'])\n",
    "df['dt_s2'] = np.where(df['year'] == 2017, np.NaN, df['score_2'] - df['score_1'])\n",
    "df['dt_z1'] = np.where(df['year'] == 2017, np.NaN, df['z_score_1'] - df['z_score_0'])\n",
    "df['dt_z2'] = np.where(df['year'] >= 2016, np.NaN, df['z_score_2'] - df['z_score_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(['gvkey1', 'year'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link SDC to COMPUSTAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SDC and Compustat Link File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The link file is from [Michael Ewens](https://github.com/michaelewens/SDC-to-Compustat-Mapping.git). Cite papers below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ```\n",
    "@article{phillips2013r,\n",
    "  title={R\\&D and the Incentives from Merger and Acquisition Activity},\n",
    "  author={Phillips, Gordon M and Zhdanov, Alexei},\n",
    "  journal={The Review of Financial Studies},\n",
    "  volume={26},\n",
    "  number={1},\n",
    "  pages={34--78},\n",
    "  year={2013},\n",
    "  publisher={Society for Financial Studies}\n",
    "  }\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "@article{ewensPetersWang2018,\n",
    " title={Acquisition prices and the measurement of intangible capital},\n",
    " author={Ewens, Michael and Peters, Ryan and Wang, Sean},\n",
    " journal={Working Paper}\n",
    " year={2018}\n",
    " }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SDC processing prohibitively slow. Work on the WRDS cloud using _sdc_link.sas_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [\"DealNumber\",\"agvkey\",\"tgvkey\",\"AMANAMES\",\"ACUSIP\",\n",
    "       \"APUBLIC\",\"ATTITUDE\",\"FORM\",\"STATUSCODE\", \"EBITLTM\",\n",
    "       \"AMV\",\"ENTVAL\",\"BOOKVALUE\",\n",
    "       \"EQVAL\",\"MV\",\"NETASS\",\"NILTM\",\"PCT_CASH\",\"PCT_STK\",\n",
    "       \"PCT_OTHER\",\"PCT_UNKNOWN\",\"PR\",\"RANKVAL\",\"SALESLTM\",\n",
    "       \"TMANAMES\",\"TNATIONCODE\",\"TPUBLIC\",\"MASTER_CUSIP\",\"TTICKER\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "type = {}\n",
    "for var in col:\n",
    "    if var in [\"DealNumber\",\"agvkey\",\"tgvkey\"]:\n",
    "        type[var] = 'Int64'\n",
    "    if var in [\"ACUSIP\",\"APUBLIC\",\"ATTITUDE\",\"FORM\",\"STATUSCODE\",\n",
    "               \"TNATIONCODE\",\"TPUBLIC\",\"MASTER_CUSIP\",\"TTICKER\"]:\n",
    "        type[var] = 'category'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdc_link = pd.read_csv('../0_data/external/sdc_gvkey.csv', \n",
    "                       header=0,\n",
    "                       parse_dates=['DATEANN','DATEEFF','DATEFIN'],\n",
    "                       dtype=type, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in [\"EBITLTM\", \"AMV\",\"ENTVAL\",\"BOOKVALUE\",\n",
    "            \"EQVAL\",\"MV\",\"NETASS\",\"NILTM\",\"PR\",\"RANKVAL\",\"SALESLTM\"]:\n",
    "    sdc_link[var] = np.where(sdc_link[var].isin(['nan', 'None', 'P', 'M']), np.NaN,\n",
    "                             sdc_link[var].str.replace(',',''))\n",
    "    sdc_link[var] = pd.to_numeric(sdc_link[var]).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60316"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sdc_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdc_link.set_index('DealNumber', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "compmna = sdc_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agvkey</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FORM</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Acq. Cert. Asts.</th>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acq. Maj. Int.</th>\n",
       "      <td>2528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acq. Part. Int.</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acq. Rem. Int.</th>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acq. of Assets</th>\n",
       "      <td>42979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acquisition</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Merger</th>\n",
       "      <td>14159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  agvkey\n",
       "FORM                    \n",
       "Acq. Cert. Asts.     240\n",
       "Acq. Maj. Int.      2528\n",
       "Acq. Part. Int.        3\n",
       "Acq. Rem. Int.       405\n",
       "Acq. of Assets     42979\n",
       "Acquisition            2\n",
       "Merger             14159"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compmna[['FORM','agvkey']].groupby('FORM').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Form of the Transaction: 10 codes describing the specific form of the transaction:\n",
    "- M (MERGER): A combination of business takes place or 100% of the stock of a public or private company is acquired.\n",
    "- A (ACQUISITION): deal in which 100% of a company is spun off or split off is classified as an acquisition by shareholders.\n",
    "- AM (ACQ OF MAJORITY INTEREST): the acquiror must have held less than 50% and be seeking to acquire 50% or more, but less than 100% of the target company’s stock.\n",
    "- AP (ACQ OF PARTIAL INTEREST): deals in which the acquiror holds less than 50% and is seeking to acquire less than 50%, or the acquiror holds over 50% and is seeking less than 100% of the target company’s stock. \n",
    "- AR (ACQ OF REMAINING INTEREST): deals in which the acquiror holds over 50% and is seeking to acquire 100% of the target company’s stock.\n",
    "- AA (ACQ OF ASSETS): deals in which the assets of a company, subsidiary, division, or branch are acquired. This code is used in all transactions when a company is being acquired and the consideration sought is not given.\n",
    "- AC: (ACQ OF CERTAIN ASSETS): deals in which sources state that “certain assets” of a company, subsidiary, or division are acquired.\n",
    "- R (RECAPITALIZATION): deals in which a company undergoes a shareholders’ Leveraged recapitalization in which the company issues a special one-time dividend (in the form of cash, debt securities, preferred stock, or assets) allowing shareholders to retain an equity interest in the company.\n",
    "- B (BUYBACK): deals in which the company buys back its equity securities or securities convertible into equity, either on the open market, through privately negotiated transactions, or through a tender offer. Board authorized repurchases are included.\n",
    "- EO (EXCHANGE OFFER): deals in which a company offers to exchange new securities for its equity securities outstanding or its securities convertible into equity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadate['lagdate'] = datadate.groupby('gvkey1')['datadate'].shift(1) + pd.DateOffset(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadate['lagdate'] = np.where(datadate['lagdate'].isna(),\n",
    "                              datadate['datadate'] - pd.DateOffset(years=1) + pd.DateOffset(days=1),\n",
    "                              datadate['lagdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gvkey1', 'fyear', 'datadate', 'year', 'lagdate']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(datadate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "compmna.to_sql('compmna', conn, index=True, if_exists='replace')\n",
    "datadate.to_sql('datadate', conn, index = True, if_exists='replace')\n",
    "qry = '''\n",
    "    select *\n",
    "    from \n",
    "        (select\n",
    "                a.*, b.datadate, b.fyear\n",
    "            from\n",
    "                compmna a left join datadate b on\n",
    "                a.agvkey == b.gvkey1 and b.datadate >= a.dateeff\n",
    "            group by \n",
    "                a.DealNumber\n",
    "        )\n",
    "        '''\n",
    "temp1 = pd.read_sql_query(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "compmna = temp1[temp1['datedif'] <= 370].drop(columns='datedif')\n",
    "\n",
    "col = list(compmna)\n",
    "col.insert(5, col.pop(col.index('datadate')))\n",
    "col.insert(6, col.pop(col.index('fyear')))\n",
    "compmna = compmna[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DealNumber               int64\n",
       "agvkey                   int64\n",
       "tgvkey                 float64\n",
       "AMANAMES                object\n",
       "ACUSIP                  object\n",
       "datadate        datetime64[ns]\n",
       "fyear                  float64\n",
       "APUBLIC                 object\n",
       "ATTITUDE                object\n",
       "FORM                    object\n",
       "STATUSCODE              object\n",
       "DATEANN         datetime64[ns]\n",
       "DATEEFF         datetime64[ns]\n",
       "DATEFIN         datetime64[ns]\n",
       "EBITLTM                float64\n",
       "AMV                    float64\n",
       "ENTVAL                 float64\n",
       "BOOKVALUE              float64\n",
       "EQVAL                  float64\n",
       "MV                     float64\n",
       "NETASS                 float64\n",
       "NILTM                  float64\n",
       "PCT_CASH               float64\n",
       "PCT_STK                float64\n",
       "PCT_OTHER              float64\n",
       "PCT_UNKNOWN            float64\n",
       "PR                     float64\n",
       "RANKVAL                float64\n",
       "SALESLTM               float64\n",
       "TMANAMES                object\n",
       "TNATIONCODE             object\n",
       "TPUBLIC                 object\n",
       "MASTER_CUSIP            object\n",
       "TTICKER                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compmna.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['tgvkey']:\n",
    "    compmna[col] = compmna[col].astype('Int64')\n",
    "for col in ['agvkey', 'tgvkey', 'ACUSIP', 'APUBLIC', 'ATTITUDE', 'FORM', 'STATUSCODE',\n",
    "             'TNATIONCODE', 'TPUBLIC', 'MASTER_CUSIP', 'TTICKER']:\n",
    "    compmna[col] = compmna[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date variables\n",
    "for col in ['datadate', 'DATEANN', 'DATEEFF', 'DATEFIN']:\n",
    "    compmna[col] = compmna[col].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "compmna.set_index('DealNumber', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SDC obsevations with logical (less than 370 day difference from effective date) Compustat _datadate_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58555"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(compmna)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-missing target sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13261"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(compmna[compmna['SALESLTM'].notnull()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing target sales but target _gvkey_ available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6630"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(compmna[(compmna['SALESLTM'].isna()) & (compmna['tgvkey'].notnull())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17842"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(compmna[(compmna['SALESLTM'].isna()) & (compmna['tgvkey'].isna()) &\n",
    "   (compmna['RANKVAL'].notnull())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agvkey                category\n",
       "tgvkey                category\n",
       "AMANAMES                object\n",
       "ACUSIP                category\n",
       "datadate        datetime64[ns]\n",
       "fyear                  float64\n",
       "APUBLIC               category\n",
       "ATTITUDE              category\n",
       "FORM                  category\n",
       "STATUSCODE            category\n",
       "DATEANN         datetime64[ns]\n",
       "DATEEFF         datetime64[ns]\n",
       "DATEFIN         datetime64[ns]\n",
       "EBITLTM                float64\n",
       "AMV                    float64\n",
       "ENTVAL                 float64\n",
       "BOOKVALUE              float64\n",
       "EQVAL                  float64\n",
       "MV                     float64\n",
       "NETASS                 float64\n",
       "NILTM                  float64\n",
       "PCT_CASH               float64\n",
       "PCT_STK                float64\n",
       "PCT_OTHER              float64\n",
       "PCT_UNKNOWN            float64\n",
       "PR                     float64\n",
       "RANKVAL                float64\n",
       "SALESLTM               float64\n",
       "TMANAMES                object\n",
       "TNATIONCODE           category\n",
       "TPUBLIC               category\n",
       "MASTER_CUSIP          category\n",
       "TTICKER               category\n",
       "dtype: object"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compmna.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct IV by acquirer's _gvkey_ and _datadate_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab acquirers' lag sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sales = compmna[(compmna['tgvkey'].notnull()) & \n",
    "                   (compmna['SALESLTM'].isna())][['agvkey', 'tgvkey', 'fyear']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agvkey</th>\n",
       "      <th>tgvkey</th>\n",
       "      <th>fyear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17095</td>\n",
       "      <td>18360</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22668</td>\n",
       "      <td>11038</td>\n",
       "      <td>1996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10719</td>\n",
       "      <td>10719</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15182</td>\n",
       "      <td>24644</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1722</td>\n",
       "      <td>5250</td>\n",
       "      <td>1997.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6625</th>\n",
       "      <td>8247</td>\n",
       "      <td>8247</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6626</th>\n",
       "      <td>9778</td>\n",
       "      <td>5439</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6627</th>\n",
       "      <td>2369</td>\n",
       "      <td>1487</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6628</th>\n",
       "      <td>164633</td>\n",
       "      <td>112112</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6629</th>\n",
       "      <td>8007</td>\n",
       "      <td>5047</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6630 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      agvkey  tgvkey   fyear\n",
       "0      17095   18360  1995.0\n",
       "1      22668   11038  1996.0\n",
       "2      10719   10719  1995.0\n",
       "3      15182   24644  1995.0\n",
       "4       1722    5250  1997.0\n",
       "...      ...     ...     ...\n",
       "6625    8247    8247  2016.0\n",
       "6626    9778    5439  2016.0\n",
       "6627    2369    1487  2016.0\n",
       "6628  164633  112112  2017.0\n",
       "6629    8007    5047  2016.0\n",
       "\n",
       "[6630 rows x 3 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_query = \"\"\"\n",
    "select distinct gvkey, datadate, fyear, sale\n",
    "from comp.funda\n",
    "where consol = %(consol)s and indfmt in %(indfmt)s \n",
    "    and datafmt = %(datafmt)s and popsrc = %(popsrc)s\n",
    "    and curcd in %(curcd)s and sale is not null\n",
    "order by gvkey, fyear\n",
    "\"\"\"\n",
    "\n",
    "parm = {'consol':('C'), 'indfmt' : ('INDL', 'FS'), 'datafmt': ('STD'), 'popsrc' : ('D'), 'curcd' : ('USD', 'CAD')}\n",
    "sale = db.raw_sql(comp_query, date_cols=['datadate'], params=parm)\n",
    "\n",
    "sale['fyear'] = sale['fyear'].astype('int16')\n",
    "sale['gvkey'] = pd.to_numeric(sale['gvkey']).astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sale.drop_duplicates(['gvkey','fyear'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sale[sale['gvkey']==112626]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sale['fyear1'] = sale['fyear'] - 1\n",
    "lagset = sale[['gvkey', 'fyear', 'sale']].copy()\n",
    "lagset.rename(columns={'fyear': 'fyear1', 'sale':'l_sale'}, inplace=True)\n",
    "sale = pd.merge(sale, lagset, on=['gvkey','fyear1'], how='left')\n",
    "\n",
    "sale.drop(columns=['fyear1'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = list(get_sales)\n",
    "col = col + ['a_sale']\n",
    "get_sales = get_sales.merge(sale, \n",
    "                            left_on=['agvkey', 'fyear'], right_on=['gvkey', 'fyear'], \n",
    "                            how='left').rename(columns={'l_sale':'a_sale'})\n",
    "\n",
    "get_sales = get_sales[col]\n",
    "col = col + ['t_sale']\n",
    "get_sales = get_sales.merge(sale, \n",
    "                            left_on=['tgvkey', 'fyear'], right_on=['gvkey', 'fyear'], \n",
    "                            how='left').rename(columns={'l_sale':'t_sale'})\n",
    "get_sales = get_sales[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sales['tgvkey'] = np.where(get_sales['tgvkey'] < 0, np.NaN, get_sales['tgvkey'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sales[get_sales['a_sale'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "compmna[compmna['agvkey'] == 112626]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Private Target Data (Chen 2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _encoding_ option allows proper string imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw = pd.read_sas('../0_data/manual/CW2019.sas7bdat', format = 'sas7bdat', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw['gvkey1'] = pd.to_numeric(cw['gvkey']).astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_priv_ dataset is a subset of _compmna_ that will be matched to Ciao-Wei's data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priv = sdc[(sdc['RANKVAL'].notnull()) & (sdc['TPUBLIC'] == 'Priv.')]\n",
    "priv.drop_duplicates(inplace=True)\n",
    "priv = priv[(priv['DATEEFF'] >= '1997-01-01') & (priv['DATEEFF'] <= '2013-12-31')]\n",
    "private = priv.compute()\n",
    "\n",
    "for var in ['DATEANN', 'DATEEFF']:\n",
    "    private[var] = pd.to_datetime(private[var]).astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below grabs all but 5 _MASTER_DEAL_NO_ from _private_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge by dates and names\n",
    "cw = cw.merge(private[['AMANAMES', 'DATEANN', 'DATEEFF', 'TMANAMES', 'MASTER_DEAL_NO']],\n",
    "         left_on=['ACQ_NAME', 'ANN', 'EFF', 'TRG_NAME'],\n",
    "         right_on=['AMANAMES', 'DATEANN', 'DATEEFF', 'TMANAMES'], how='left')\n",
    "col = list(cw)\n",
    "col.insert(0, col.pop())\n",
    "cw = cw[col]\n",
    "\n",
    "cw.drop(columns=['AMANAMES', 'DATEANN', 'DATEEFF', 'TMANAMES'], inplace=True)\n",
    "\n",
    "cw.drop_duplicates(inplace=True)\n",
    "\n",
    "# review dates and names of the missing\n",
    "missing = private[['MASTER_DEAL_NO', 'AMANAMES', 'DATEANN', 'DATEEFF', 'TMANAMES']].merge(cw[cw['MASTER_DEAL_NO'].isna()][['ANN', 'EFF', 'ACQ_NAME', 'TRG_NAME']],\n",
    "                                                           how='right',left_on=['DATEANN', 'DATEEFF'], right_on=['ANN', 'EFF'])\n",
    "\n",
    "missing.drop_duplicates(inplace=True)\n",
    "missing.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# manual match\n",
    "missing = missing.iloc[[0, 1, 5, 16, 24, 26, 28, 29, 39, 44, 53]][['MASTER_DEAL_NO', 'ANN', 'EFF', 'ACQ_NAME', 'TRG_NAME']]\n",
    "\n",
    "# update MASTER_DEAL_NO\n",
    "cw = cw.merge(missing, \n",
    "         left_on=['ACQ_NAME', 'ANN', 'EFF', 'TRG_NAME'],\n",
    "         right_on=['ACQ_NAME', 'ANN', 'EFF', 'TRG_NAME'], how='left', suffixes=('','_y'))\n",
    "\n",
    "cw['MASTER_DEAL_NO'] = np.where(cw['MASTER_DEAL_NO'].isna(), cw['MASTER_DEAL_NO_y'], cw['MASTER_DEAL_NO'])\n",
    "\n",
    "cw.drop(columns=['MASTER_DEAL_NO_y'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = list(cw)\n",
    "col.insert(1, col.pop())\n",
    "cw = cw[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw.to_sql('compmna', conn, index=False, if_exists='replace')\n",
    "datadate.to_sql('datadate', conn, index = True, if_exists='replace')\n",
    "qry = '''\n",
    "    select  \n",
    "        a.*, b.datadate\n",
    "    from\n",
    "        compmna a join datadate b on\n",
    "        a.gvkey1 == b.gvkey1 and a.EFF between b.lagdate and b.datadate \n",
    "    '''\n",
    "cw = pd.read_sql_query(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw['datadate'] = pd.to_datetime(cw['datadate']).astype('datetime64[ns]')\n",
    "\n",
    "cw['year'] = cw['datadate'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql('avg_sim', conn, index=False, if_exists='replace')\n",
    "cw.to_sql('cw', conn, index = False, if_exists='replace')\n",
    "qry = '''\n",
    "    select  \n",
    "        a.*\n",
    "    from\n",
    "        avg_sim a join (select distinct gvkey1, year from cw) b\n",
    "        on a.gvkey1 = b.gvkey1 and a.year = b.year\n",
    "    '''\n",
    "cw_sim = pd.read_sql_query(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_sim = cw_sim[['gvkey1', 'year', 'dt_s1', 'dt_z1', 'dt_s2', 'dt_z2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnic_industry.to_sql('tnic', conn, index=True, if_exists='replace')\n",
    "cw_sim.to_sql('cw_sim', conn, index = False, if_exists='replace')\n",
    "qry = '''\n",
    "    select  \n",
    "        a.gvkey1, a.year, a.gvkey2\n",
    "    from\n",
    "        tnic a join (select distinct gvkey1, year from cw_sim) b\n",
    "        on a.gvkey1 = b.gvkey1 and a.year = b.year\n",
    "    '''\n",
    "cw_tnic = pd.read_sql_query(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_tnic = cw_tnic.merge(df[['gvkey1', 'year', 'dt_s1', 'dt_s2', 'dt_z1', 'dt_z2']]\n",
    "                        , left_on=['gvkey2', 'year'], right_on=['gvkey1', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_tnic.drop(columns=['gvkey1_y'], inplace=True)\n",
    "cw_tnic.rename(columns={'gvkey1_x':'gvkey1'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnic_avg = cw_tnic.groupby(['gvkey1', 'year']).mean().drop(columns=['gvkey2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_sim = cw_sim.merge(tnic_avg, left_on=['gvkey1', 'year'], right_on=['gvkey1', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_sim['dt_s1'] = cw_sim['dt_s1_x'] - cw_sim['dt_s1_y']\n",
    "cw_sim['dt_z1'] = cw_sim['dt_z1_x'] - cw_sim['dt_z1_y']\n",
    "cw_sim['dt_s2'] = cw_sim['dt_s2_x'] - cw_sim['dt_s2_y']\n",
    "cw_sim['dt_z2'] = cw_sim['dt_z2_x'] - cw_sim['dt_z2_y'] \n",
    "# cw_sim = cw_sim[['gvkey1', 'year', 'dt_s1', 'dt_z1', 'dt_s2', 'dt_z2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw = cw.merge(cw_sim, left_on=['gvkey1', 'year'], right_on=['gvkey1', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw.to_stata('/Users/ohn0000/Dropbox/Project/cko/2_pipeline/cw.dta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Materiality of M&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "material = pd.read_csv('/Users/ohn0000/Project/cko/0_data/external/materiality.csv')\n",
    "material.set_index([\"year\", \"gvkey1\"], inplace=True, verify_integrity=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful since the _year_ here refers to the M&A firm-year. The _year_ in __avg_sim__ is the year competitors are identified. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M&A Disclosure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = pd.read_csv('/Users/ohn0000/Project/cko/0_data/manual/disc.csv', parse_dates=['DATADATE'])\n",
    "disc['CIK'] = disc['CIK'].apply(lambda x: str(int(x)).zfill(10) if pd.notnull(x) else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disclosure also might need additonal data collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc.rename(columns={\"GVKEY\":\"gvkey1\", \"FYEAR\":\"year\"}, inplace=True)\n",
    "disc.set_index([\"year\", \"gvkey1\"], inplace=True, verify_integrity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual = disc.join(material)[['DATADATE', 'CIK', 'TGTAT_ACQAT', 'TGTDVAL_ACQAT', 'MD_A', 'PROFORMA']].sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wrds\n",
    "db = wrds.Connection(wrds_username = \"yaera\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_details_desc = db.describe_table('sdc', 'ma_details').sort_values('name')\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    print(ma_details_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|     Variable | Description                    |\n",
    "|:------------:|:-------------------------------|\n",
    "|bookvalue     |Target Book Value (\\$mil)       |\n",
    "|compete       |Competing Bidder (Y/N)          |\n",
    "|competecode   |Competing Bid Deal Code         |  \n",
    "|dateann       |Date Announced                  |\n",
    "|dateannest    |_dateann_ is estimated (Y/N)    | \n",
    "|dateeff       |Date Effective                  | \n",
    "|ebitltm       |Target EBIT LTM (\\$mil)         |\n",
    "|pct_cash      |Percentage of consideration paid in cash|\n",
    "|pct_other|Percentage of consideration paid in other then cash or stock|\n",
    "|pct_stk|Percentage of consideration paid in stock|\n",
    "|pct_unknown|Percentage of consideration which is unknown|\n",
    "|ptincltm|Target Pre-Tax Income LTM (\\$mil)|\n",
    "|salesltm|Target Sales LTM (\\$mil)|\n",
    "|rankval|Ranking Value incl Net Debt of Target (\\$mil)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run sql query below on _WRDS_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wrds\n",
    "# sdc_query = \"\"\"\n",
    "# select master_deal_no as DealNumber, \n",
    "#         bookvalue, \n",
    "#         compete, \n",
    "#         competecode, \n",
    "#         dateann, \n",
    "#         dateannest, \n",
    "#         dateeff, \n",
    "#         ebitltm, \n",
    "#         pct_cash,\n",
    "#         pct_other,\n",
    "#         pct_stk,\n",
    "#         pct_unknown,\n",
    "#         ptincltm,\n",
    "#         salesltm,\n",
    "#         rankval\n",
    "# from sdc.ma_details\n",
    "# where dateeff is not null \n",
    "# \"\"\"\n",
    "# # and master_deal_no in %(deal_no)s\n",
    "# sdc = db.raw_sql(sdc_query, date_cols=['dateann', 'dateeff'])\n",
    "# sdc.to_pickle('/home/upenn/yaera/sdc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdc = pd.read_pickle('/Users/ohn0000/Project/cko/0_data/external/sdc.pkl')\n",
    "sdc.drop_duplicates('dealnumber', inplace = True)\n",
    "sdc['dealnumber'] = sdc['dealnumber'].astype('int64')\n",
    "\n",
    "# clear up values and change dtype to 'float'\n",
    "for column in ['bookvalue', 'ebitltm', 'pct_cash', 'pct_other', 'pct_stk', 'pct_unknown', 'ptincltm', 'salesltm', 'rankval']:\n",
    "    sdc[column] = sdc[column].apply(lambda x: np.NaN if x == '*********' else (np.NaN if pd.isna(x) else (float(x.replace(',', '')) if isinstance(x, str) else float(x))))\n",
    "    sdc[column].astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdc_sub = pd.merge(sdc_link, sdc,\n",
    "                   left_index=True, right_on='dealnumber').drop('dealnumber', axis='columns')\n",
    "sdc_sub.index.name = 'dealnumber'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdc_sub.sort_values(['agvkey', 'dateeff'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdc_link['agvkey'].count() / sdc['dealnumber'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdc_sub['agvkey'].count() / sdc_link['agvkey'].count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdc_sub.profile_report(style={'full_width':True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use __compustat__ _datadate_ and gvkey to link the sdc data to the similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wrds\n",
    "db = wrds.Connection(wrds_username = 'hohn')\n",
    "\n",
    "sdc_quary = \"\"\"\n",
    "select gvkey, datadate, fyear, cusip,  cik\n",
    "from comp.funda\n",
    "where consol = %(consol)s and indfmt in %(indfmt)s and datafmt = %(datafmt)s and popsrc = %(popsrc)s and curcd in %(curcd)s\n",
    "\"\"\"\n",
    "\n",
    "parm = {'consol':('C'), 'indfmt' : ('INDL', 'FS'), 'datafmt': ('STD'), 'popsrc' : ('D'), 'curcd' : ('USD', 'CAD')}\n",
    "\n",
    "funda = db.raw_sql(sdc_quary, params = parm, date_cols = ['datadate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funda['start'] = funda['datadate'] - pd.DateOffset(months = 12) + pd.DateOffset(days = 1)\n",
    "funda['gvkey'] = funda['gvkey'].astype('int64')\n",
    "funda.set_index('gvkey', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funda.fyear = funda.fyear.astype('Int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandasql as ps\n",
    "\n",
    "sql_query = '''\n",
    "select a.*, b.datadate, b.fyear, b.cusip, b.cik\n",
    "from sdc_sub a left join funda b\n",
    "on a.agvkey = b.gvkey and a.dateeff between b.start and b.datadate\n",
    "'''\n",
    "\n",
    "newdf = ps.sqldf(sql_query, locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = list(newdf)\n",
    "for i in range(2, 6):\n",
    "    col.insert(i, col.pop(-1))\n",
    "newdf = newdf.loc[:,col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['datadate', 'dateann', 'dateeff']:\n",
    "    newdf[i] = newdf[i].astype('datetime64[ns]')\n",
    "    \n",
    "newdf['year'] = newdf['datadate'].dt.year.astype('Int16')\n",
    "for i in ['fyear', 'agvkey', 'tgvkey']:\n",
    "    newdf[i] = newdf[i].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = list(newdf)\n",
    "col.insert(col.index('datadate'), col.pop(col.index('year')))\n",
    "newdf = newdf.loc[:,col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = newdf.drop_duplicates(subset='dealnumber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf[newdf['agvkey'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf['rankval'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18994 observations with non-missing _rankval_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf['salesltm'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8055 observations with non-missing _salesltm_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(newdf['rankval'].notnull() & newdf['salesltm'].notnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6445 observations with both _rankval_ and _salesltm_ available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append similarity score between acquirer and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload = newdf[newdf['agvkey'].notnull() & newdf['tgvkey'].notnull() & newdf['year'].notnull()][['agvkey', 'tgvkey', 'year']].rename(columns={'agvkey':'gvkey1', 'tgvkey':'gvkey2'})\n",
    "upload.to_csv('/Users/ohn0000/Project/cko/2_pipeline/upload.csv', index=False)\n",
    "!scp /Users/ohn0000/Project/cko/2_pipeline/upload.csv $WRDS:/scratch/ou/hohn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this on wrds server. The __TNIC_All__ files should be uploaded in scratch beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The server killed the previous code that joins after combines all files. The current code instead loop over the files.\n",
    "\"\"\"\n",
    "# !cd /scratch/ou/hohn/TNIC_AllPairsDistrib\n",
    "# !cat tnicall1996.txt > tnicall_combined.txt\n",
    "# !for file in tnicall{1997..2017}.txt; do sed '1d' $file >> tnicall_combined.txt; done\n",
    "# !cd ~\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "atsim.py\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scp atsim.py $WRDS:~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scp $WRDS:/scratch/ou/hohn/atsim.csv /Users/ohn0000/Project/cko/2_pipeline/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = list(newdf)\n",
    "col.insert(col.index('bookvalue'), col.pop(col.index('atsim')))\n",
    "newdf = newdf.loc[:,col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV candidates\n",
    "\n",
    "The materiality measure based on deal value will be the last resort for the IV.   \n",
    "Alternatively, 2SLS using multiple IVs is feasible.\n",
    "\n",
    "Candidates\n",
    "* Max deal value\n",
    "* Sum deal value\n",
    "* Datedif between _dateeff_ and _datadate_\n",
    "    * _dateeff_ of the first M&A\n",
    "    * _dateeff_ of the largest M&A\n",
    "    * weighted average of _dateeff_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-sections\n",
    "* Similarity between acquirer and target \n",
    "    - Relation stronger in diversifying\n",
    "    - Could be more of a U-shaped relation, i.e., competitors don't follow when you move far enough\n",
    "* Average value of pre-similarities between acquirer and close competitors \n",
    "    - Prediction not clear\n",
    "* M&A performance during the completed firm-year\n",
    "    - Relation stronger when M&A was more successful <-> how do we define success of an M&A?\n",
    "* Number of close competitors of the target\n",
    "    - Potential targets are candidates of future mergers\n",
    "* How many competitors were there initially?\n",
    "    - The size of the TNIC industry"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "450px",
    "left": "1518px",
    "right": "20px",
    "top": "120px",
    "width": "382px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
