{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CKO JAR Revision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rpy2.rinterface #ggplot tool\n",
    "from pandas_profiling import ProfileReport\n",
    "import dask.dataframe as dd\n",
    "import wrds\n",
    "import pandasql as ps\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Review TNIC-3 data\n",
    "\n",
    "# ### Import TNIC3 data from Hoberg and Philips data library \n",
    "\n",
    "# # !wget -P ../2_pipeline/ http://hobergphillips.tuck.dartmouth.edu/idata/tnic3_data.zip\n",
    "# # !unzip -q ../2_pipeline/tnic3_data.zip -d ../2_pipeline/ && rm ../2_pipeline/tnic3_data.zip\n",
    "\n",
    "# \"\"\"\n",
    "# Hoberg and Philips TNIC3 database\n",
    "# \"\"\"\n",
    "# tnic = pd.read_csv('/Users/ohn0000/Dropbox/Project/cko/0_data/external/tnic3_data.txt', \n",
    "#                    delimiter='\\t', header=0, index_col=['gvkey1', 'year', 'gvkey2'])\n",
    "# tnic.dropna(inplace=True)\n",
    "\n",
    "# ### Subset to 20-closest competitors\n",
    "\n",
    "# # tnic_industry = tnic.groupby(level=['gvkey1', 'year'])[\"score\"].nlargest(20).reset_index(level=[0,1], drop=True)\n",
    "# # tnic_industry = tnic_industry.to_frame(name='score')\n",
    "# # tnic_industry.to_pickle('../2_pipeline/tnic_industry.pkl')\n",
    "# tnic_industry = pd.read_pickle('../2_pipeline/tnic_industry.pkl')\n",
    "\n",
    "# ```tnic_industry``` still has firm-years with less than 20 competitors.\n",
    "\n",
    "# # \"\"\"\n",
    "# # Require at least 20 closest competitors\n",
    "# # \"\"\"\n",
    "# # tnicind_sub = tnic.groupby(level=['gvkey1', 'year'])[\"score\"].filter(lambda x: x.size == 20)\n",
    "# # tnicind_sub = tnicind_sub.to_frame(name='score')\n",
    "\n",
    "# \"\"\"\n",
    "# tnic_industry['gvkey1'] = tnic_industry['gvkey1'].apply(lambda x: str(x).zfill(6))\n",
    "# tnic_industry['gvkey2'] = tnic_industry['gvkey2'].apply(lambda x: str(x).zfill(6))\n",
    "# \"\"\"\n",
    "\n",
    "# Remeber that _year_ in __tnic_industry__ is the base year for identifying close competitors. Accordingly, _lead1_ is the M&A year and _lead2_ is the year following M&A.\n",
    "\n",
    "# Readme_tnic3.txt explains that _year_ equals the first four digits of the __compustat__ _datadate_.\n",
    "\n",
    "# ### Shift years in __tnic_industry__ to get _lead1_ and _lead2_ similarity scores\n",
    "\n",
    "# tnic_industry.rename(columns={'score':'score_0'}, inplace=True)\n",
    "\n",
    "# for i in range(1,3):\n",
    "#     colname = 'score' + '_' + str(i)\n",
    "#     tnic_industry['score'] = np.NaN\n",
    "#     tnic_industry.index = tnic_industry.index.set_levels(tnic_industry.index.levels[1] + 1, level=1)\n",
    "#     tnic_industry.update(tnic)\n",
    "#     tnic_industry.rename(columns={'score':colname}, inplace=True)\n",
    "\n",
    "# tnic_industry.reset_index(inplace=True)\n",
    "# tnic_industry[\"year\"] -= 2\n",
    "# tnic_industry.set_index([\"gvkey1\", \"year\", \"gvkey2\"], inplace=True)\n",
    "\n",
    "# tnic_industry.to_pickle('../2_pipeline/tnic_industry.pkl')\n",
    "\n",
    "# ### Run __*tnic_industry.py*__ on _WRDS_ to update lead scores\n",
    "\n",
    "# Many of the _lead1_ and _lead2_ values are missing. Grab these values from __TNIC_Advanced__ uploaded on _WRDS_. \n",
    "\n",
    "# # !scp ../2_pipeline/tnic_industry.pkl tnic_industry.py $WRDS:~\n",
    "\n",
    "# ### Download updated __*tnic_industry*__ file from WRDS\n",
    "\n",
    "# # !scp $WRDS:/scratch/ou/hohn/tnic_ind_update.pkl ../2_pipeline/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnic_industry = pd.read_pickle('../2_pipeline/tnic_ind_update.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average TNIC similarity score across 20-closest competitors.  \n",
    "Remeber that in __TNIC_ALL__ most of the scores equals to zero. The _z\\__ might be the more suitable.\n",
    "- Close pair in t0 not appearing in t1 or t2 is meaningful.\n",
    "- __BE CAREFUL__ of year 2016 and 2017. __TNIC is available only up to 2017__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sim = tnic_industry.groupby(level=['gvkey1','year']).mean()\n",
    "avg_sim = avg_sim.join(tnic_industry.groupby(level=['gvkey1','year']).count().add_prefix(\"n_\"))\n",
    "avg_sim = avg_sim.join(tnic_industry.fillna(0).groupby(level=['gvkey1','year']).mean().add_prefix(\"z_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109791"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(avg_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab COMPUSTAT _datadate_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revise here if _avg\\_sim_ needs additional COMPUSTAT variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading library list...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "db = wrds.Connection(wrds_username='yaera')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_query = \"\"\"\n",
    "select distinct gvkey, datadate, fyear, indfmt, sale\n",
    "from comp.funda\n",
    "where consol = %(consol)s and indfmt in %(indfmt)s \n",
    "    and datafmt = %(datafmt)s and popsrc = %(popsrc)s\n",
    "    and curcd in %(curcd)s\n",
    "order by gvkey, fyear\n",
    "\"\"\"\n",
    "\n",
    "parm = {'consol':('C'), 'indfmt' : ('INDL', 'FS'), 'datafmt': ('STD'), 'popsrc' : ('D'), 'curcd' : ('USD', 'CAD')}\n",
    "comp = db.raw_sql(comp_query, date_cols=['datadate'], params=parm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp['fyear'] = comp['fyear'].astype('int16')\n",
    "comp['year'] = comp['datadate'].dt.year.astype('int16')\n",
    "\n",
    "comp['gvkey1'] = pd.to_numeric(comp['gvkey']).astype('int64')\n",
    "comp.drop(columns='gvkey', inplace=True)\n",
    "\n",
    "comp.set_index(['gvkey1', 'fyear'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not sure how TNIC deals fiscal years where fyear are differenct but\n",
    "year are the same. Assume the lastest datadate within _year_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadate = comp[~comp.index.duplicated(keep='last')][['datadate', 'year']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sim = pd.merge(avg_sim, datadate, \n",
    "                 left_index=True, \n",
    "                 right_on=['gvkey1', 'year'], how='left').drop_duplicates(['gvkey1', 'year'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sim = avg_sim[avg_sim['datadate'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TNIC data not missing _datadate_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109757"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(avg_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = list(avg_sim)\n",
    "col = col[-4:] + col[:-4]\n",
    "avg_sim = avg_sim[col].sort_values(['gvkey1', 'year', 'datadate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gvkey1</th>\n",
       "      <th>fyear</th>\n",
       "      <th>datadate</th>\n",
       "      <th>year</th>\n",
       "      <th>score_0</th>\n",
       "      <th>score_1</th>\n",
       "      <th>score_2</th>\n",
       "      <th>n_score_0</th>\n",
       "      <th>n_score_1</th>\n",
       "      <th>n_score_2</th>\n",
       "      <th>z_score_0</th>\n",
       "      <th>z_score_1</th>\n",
       "      <th>z_score_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1004</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>1995-05-31</td>\n",
       "      <td>1995</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.123100</td>\n",
       "      <td>0.069600</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.123100</td>\n",
       "      <td>0.069600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1004</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>1996-05-31</td>\n",
       "      <td>1996</td>\n",
       "      <td>0.020830</td>\n",
       "      <td>0.043288</td>\n",
       "      <td>0.048657</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.020830</td>\n",
       "      <td>0.034630</td>\n",
       "      <td>0.034060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1004</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>1997-05-31</td>\n",
       "      <td>1997</td>\n",
       "      <td>0.028105</td>\n",
       "      <td>0.043850</td>\n",
       "      <td>0.050993</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>0.028105</td>\n",
       "      <td>0.035080</td>\n",
       "      <td>0.035695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1004</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>1998-05-31</td>\n",
       "      <td>1998</td>\n",
       "      <td>0.015110</td>\n",
       "      <td>0.037587</td>\n",
       "      <td>0.048100</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>0.015110</td>\n",
       "      <td>0.028190</td>\n",
       "      <td>0.031265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1004</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>1999-05-31</td>\n",
       "      <td>1999</td>\n",
       "      <td>0.019539</td>\n",
       "      <td>0.031507</td>\n",
       "      <td>0.049440</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0.019539</td>\n",
       "      <td>0.026256</td>\n",
       "      <td>0.041200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    gvkey1   fyear   datadate  year   score_0   score_1   score_2  n_score_0  \\\n",
       "77    1004  1994.0 1995-05-31  1995  0.005800  0.123100  0.069600          1   \n",
       "78    1004  1995.0 1996-05-31  1996  0.020830  0.043288  0.048657         10   \n",
       "79    1004  1996.0 1997-05-31  1997  0.028105  0.043850  0.050993         20   \n",
       "80    1004  1997.0 1998-05-31  1998  0.015110  0.037587  0.048100         20   \n",
       "81    1004  1998.0 1999-05-31  1999  0.019539  0.031507  0.049440         18   \n",
       "\n",
       "    n_score_1  n_score_2  z_score_0  z_score_1  z_score_2  \n",
       "77          1          1   0.005800   0.123100   0.069600  \n",
       "78          8          7   0.020830   0.034630   0.034060  \n",
       "79         16         14   0.028105   0.035080   0.035695  \n",
       "80         15         13   0.015110   0.028190   0.031265  \n",
       "81         15         15   0.019539   0.026256   0.041200  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_sim.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab _permno_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revise here if _avg\\_sim_ needs additional CRSP variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query= \"\"\"\n",
    "select gvkey, liid as iid, lpermno as permno, linkdt, linkenddt\n",
    "from crsp.ccmxpf_linktable\n",
    "where linktype in %(type)s and linkprim in %(prim)s and usedflag = 1\n",
    "\"\"\"\n",
    "\n",
    "parm = {'type':('LU', 'LC'), 'prim':('P', 'C')}\n",
    "linktable = db.raw_sql(sql_query, date_cols=['linkdt', 'linkenddt'], params=parm)\n",
    "\n",
    "linktable['gvkey'] = pd.to_numeric(linktable['gvkey'])\n",
    "linktable['permno'] = pd.to_numeric(linktable['permno']).astype('int64')\n",
    "linktable['iid'] = linktable['iid'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "enddt = pd.to_datetime('2020-01-07 00:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "linktable['linkenddt'] = linktable['linkenddt'].fillna(value = enddt)\n",
    "linktable['linkenddt'] = linktable['linkenddt'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(':memory:')\n",
    "avg_sim.to_sql('avg_sim', conn, index=False)\n",
    "linktable.to_sql('linktable', conn, index=False)\n",
    "\n",
    "qry = '''\n",
    "    select  \n",
    "        avg_sim.*, linktable.permno\n",
    "    from\n",
    "        avg_sim left join linktable on\n",
    "        avg_sim.datadate between linkdt and linkenddt and avg_sim.gvkey1 = linktable.gvkey\n",
    "    '''\n",
    "df = pd.read_sql_query(qry, conn)\n",
    "df['permno'] = df['permno'].astype('Int64')\n",
    "df['datadate'] = df['datadate'].astype('datetime64[ns]')\n",
    "\n",
    "df[df['permno'].isna()].to_sql('df', conn, index=False)\n",
    "\n",
    "qry = '''\n",
    "    select\n",
    "        a.*, b.gvkey1, b.datadate\n",
    "        from linktable a join df b\n",
    "        on \n",
    "            a.gvkey = b.gvkey1\n",
    "'''\n",
    "aug = pd.read_sql_query(qry, conn)\n",
    "\n",
    "aug.to_sql('aug', conn, index=False)\n",
    "qry = '''\n",
    "    select gvkey1, permno, iid, min(linkdt) as linkdt, max(linkenddt) as linkenddt\n",
    "    from aug\n",
    "    group by gvkey1, permno, iid\n",
    "    order by gvkey1, linkdt\n",
    "'''\n",
    "\n",
    "df = df.merge(aug[aug['iid'].isin(['01','02'])].rename(columns={'permno':'permno1'})[['gvkey1', 'permno1']], \n",
    "         left_on = ['gvkey1'], right_on=['gvkey1'], how='left')\n",
    "df['permno'] = np.where(df['permno'].isna(), df['permno1'], df['permno'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(['gvkey1', 'year']).drop(columns='permno1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = list(df)\n",
    "col.insert(2, col.pop(col.index('permno')))\n",
    "df = df[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dt_s1'] = np.where(df['year'] == 2017, np.NaN, df['score_1'] - df['score_0'])\n",
    "df['dt_s2'] = np.where(df['year'] == 2017, np.NaN, df['score_2'] - df['score_1'])\n",
    "df['dt_z1'] = np.where(df['year'] == 2017, np.NaN, df['z_score_1'] - df['z_score_0'])\n",
    "df['dt_z2'] = np.where(df['year'] >= 2016, np.NaN, df['z_score_2'] - df['z_score_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(['gvkey1', 'year'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link SDC to COMPUSTAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SDC and Compustat Link File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The link file is from [Michael Ewens](https://github.com/michaelewens/SDC-to-Compustat-Mapping.git). Cite papers below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ```\n",
    "@article{phillips2013r,\n",
    "  title={R\\&D and the Incentives from Merger and Acquisition Activity},\n",
    "  author={Phillips, Gordon M and Zhdanov, Alexei},\n",
    "  journal={The Review of Financial Studies},\n",
    "  volume={26},\n",
    "  number={1},\n",
    "  pages={34--78},\n",
    "  year={2013},\n",
    "  publisher={Society for Financial Studies}\n",
    "  }\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "@article{ewensPetersWang2018,\n",
    " title={Acquisition prices and the measurement of intangible capital},\n",
    " author={Ewens, Michael and Peters, Ryan and Wang, Sean},\n",
    " journal={Working Paper}\n",
    " year={2018}\n",
    " }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SDC processing prohibitively slow. Work on the WRDS cloud using _sdc_link.sas_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [\"DealNumber\",\"agvkey\",\"tgvkey\",\"AMANAMES\",\"ACUSIP\",\n",
    "       \"APUBLIC\",\"ATTITUDE\",\"FORM\",\"STATUSCODE\", \"EBITLTM\",\n",
    "       \"AMV\",\"ENTVAL\",\"BOOKVALUE\",\n",
    "       \"EQVAL\",\"MV\",\"NETASS\",\"NILTM\",\"PCT_CASH\",\"PCT_STK\",\n",
    "       \"PCT_OTHER\",\"PCT_UNKNOWN\",\"PR\",\"RANKVAL\",\"SALESLTM\",\n",
    "       \"TMANAMES\",\"TNATIONCODE\",\"TPUBLIC\",\"MASTER_CUSIP\",\"TTICKER\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "type = {}\n",
    "for var in col:\n",
    "    if var in [\"DealNumber\",\"agvkey\",\"tgvkey\"]:\n",
    "        type[var] = 'Int64'\n",
    "    if var in [\"ACUSIP\",\"APUBLIC\",\"ATTITUDE\",\"FORM\",\"STATUSCODE\",\n",
    "               \"TNATIONCODE\",\"TPUBLIC\",\"MASTER_CUSIP\",\"TTICKER\"]:\n",
    "        type[var] = 'category'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdc_link = pd.read_csv('../0_data/external/sdc_gvkey.csv', \n",
    "                       header=0,\n",
    "                       parse_dates=['DATEANN','DATEEFF','DATEFIN'],\n",
    "                       dtype=type, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in [\"EBITLTM\", \"AMV\",\"ENTVAL\",\"BOOKVALUE\",\n",
    "            \"EQVAL\",\"MV\",\"NETASS\",\"NILTM\",\"PR\",\"RANKVAL\",\"SALESLTM\"]:\n",
    "    sdc_link[var] = np.where(sdc_link[var].isin(['nan', 'None', 'P', 'M']), np.NaN,\n",
    "                             sdc_link[var].str.replace(',',''))\n",
    "    sdc_link[var] = pd.to_numeric(sdc_link[var]).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdc_link = sdc_link[sdc_link['agvkey'] != sdc_link['tgvkey']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdc_link.set_index('DealNumber', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "compmna = sdc_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agvkey</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FORM</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Acq. Cert. Asts.</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acq. Maj. Int.</th>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acq. Part. Int.</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acq. Rem. Int.</th>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acq. of Assets</th>\n",
       "      <td>7744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acquisition</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Merger</th>\n",
       "      <td>5080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  agvkey\n",
       "FORM                    \n",
       "Acq. Cert. Asts.      69\n",
       "Acq. Maj. Int.       499\n",
       "Acq. Part. Int.        1\n",
       "Acq. Rem. Int.       163\n",
       "Acq. of Assets      7744\n",
       "Acquisition            2\n",
       "Merger              5080"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compmna[['FORM','agvkey']].groupby('FORM').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop _AP_ and _AR_.\n",
    "\n",
    "Form of the Transaction: 10 codes describing the specific form of the transaction:\n",
    "- M (MERGER): A combination of business takes place or 100% of the stock of a public or private company is acquired.\n",
    "- A (ACQUISITION): deal in which 100% of a company is spun off or split off is classified as an acquisition by shareholders.\n",
    "- AM (ACQ OF MAJORITY INTEREST): the acquiror must have held less than 50% and be seeking to acquire 50% or more, but less than 100% of the target company’s stock.\n",
    "- AP (ACQ OF PARTIAL INTEREST): deals in which the acquiror holds less than 50% and is seeking to acquire less than 50%, or the acquiror holds over 50% and is seeking less than 100% of the target company’s stock. \n",
    "- AR (ACQ OF REMAINING INTEREST): deals in which the acquiror holds over 50% and is seeking to acquire 100% of the target company’s stock.\n",
    "- AA (ACQ OF ASSETS): deals in which the assets of a company, subsidiary, division, or branch are acquired. This code is used in all transactions when a company is being acquired and the consideration sought is not given.\n",
    "- AC: (ACQ OF CERTAIN ASSETS): deals in which sources state that “certain assets” of a company, subsidiary, or division are acquired.\n",
    "- R (RECAPITALIZATION): deals in which a company undergoes a shareholders’ Leveraged recapitalization in which the company issues a special one-time dividend (in the form of cash, debt securities, preferred stock, or assets) allowing shareholders to retain an equity interest in the company.\n",
    "- B (BUYBACK): deals in which the company buys back its equity securities or securities convertible into equity, either on the open market, through privately negotiated transactions, or through a tender offer. Board authorized repurchases are included.\n",
    "- EO (EXCHANGE OFFER): deals in which a company offers to exchange new securities for its equity securities outstanding or its securities convertible into equity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "compmna = compmna[~compmna['FORM'].isin(['Acq. Part. Int.','Acq. Rem. Int.'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadate['lagdate'] = datadate.groupby('gvkey1')['datadate'].shift(1) + pd.DateOffset(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadate['lagdate'] = np.where(datadate['lagdate'].isna(),\n",
    "                              datadate['datadate'] - pd.DateOffset(years=1) + pd.DateOffset(days=1),\n",
    "                              datadate['lagdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "compmna.to_sql('compmna', conn, index=True, if_exists='replace')\n",
    "datadate.to_sql('datadate', conn, index = True, if_exists='replace')\n",
    "qry = '''\n",
    "    select *\n",
    "    from \n",
    "        (select\n",
    "                a.*, b.datadate, b.fyear\n",
    "            from\n",
    "                compmna a left join datadate b on\n",
    "                a.agvkey == b.gvkey1 and b.datadate >= a.dateeff\n",
    "            group by \n",
    "                a.DealNumber\n",
    "        )\n",
    "        '''\n",
    "temp1 = pd.read_sql_query(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['tgvkey', 'fyear']:\n",
    "    temp1[col] = temp1[col].astype('Int64')\n",
    "for col in ['agvkey', 'tgvkey', 'ACUSIP', 'APUBLIC', 'ATTITUDE', 'FORM', 'STATUSCODE',\n",
    "             'TNATIONCODE', 'TPUBLIC', 'MASTER_CUSIP', 'TTICKER']:\n",
    "    temp1[col] = temp1[col].astype('category')\n",
    "for col in ['datadate', 'DATEANN', 'DATEEFF', 'DATEFIN']:\n",
    "    temp1[col] = temp1[col].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "compmna = temp1[(temp1['datadate'] - temp1['DATEEFF']).dt.days <= 370]\n",
    "\n",
    "col = list(compmna)\n",
    "col.insert(5, col.pop(col.index('datadate')))\n",
    "col.insert(6, col.pop(col.index('fyear')))\n",
    "compmna = compmna[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "compmna.set_index('DealNumber', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SDC obsevations with logical (less than 370 day difference from effective date) Compustat _datadate_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13072"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(compmna)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-missing target sales + Missing target sales but target _gvkey_ available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12884"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(compmna[compmna['SALESLTM'].notnull()]) + len(compmna[(compmna['SALESLTM'].isna()) & (compmna['tgvkey'].notnull())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct IV by acquirer's _gvkey_ and _datadate_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab Compustat Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "sale = comp[comp['sale'].notnull() & comp['sale']!=0][['sale']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "compmna.to_sql('compmna', conn, index=True, if_exists='replace')\n",
    "\n",
    "sale.to_sql('sale', conn, index=True, if_exists='replace')\n",
    "qry = '''\n",
    "        select a.*, b.sale as a_sale, b.fyear as amatch\n",
    "        from compmna a left join sale b\n",
    "        on a.agvkey = b.gvkey1 and b.fyear =  \n",
    "        (select fy.fyear \n",
    "            from sale as fy \n",
    "            where a.agvkey = fy.gvkey1 and fy.fyear < a.fyear\n",
    "            order by fy.fyear desc\n",
    "            limit 1\n",
    "        )\n",
    "        '''\n",
    "temp = pd.read_sql_query(qry, conn)\n",
    "temp.to_sql('temp', conn, index=True, if_exists='replace')\n",
    "\n",
    "qry = '''\n",
    "        select a.*, b.sale as t_sale, b.fyear as tmatch\n",
    "        from temp a left join sale b\n",
    "        on a.tgvkey = b.gvkey1 and b.fyear =  \n",
    "        (select fy.fyear \n",
    "            from sale as fy \n",
    "            where a.tgvkey = fy.gvkey1 and fy.fyear < a.fyear\n",
    "            order by fy.fyear desc\n",
    "            limit 1\n",
    "        )\n",
    "        '''\n",
    "compmna = pd.read_sql_query(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['agvkey', 'tgvkey']:\n",
    "    compmna[col] = pd.to_numeric(compmna[col]).astype('Int64')\n",
    "for col in ['fyear', 'amatch', 'tmatch']:\n",
    "    compmna[col] = compmna[col].astype('Int64')\n",
    "for col in ['agvkey', 'tgvkey', 'ACUSIP', 'APUBLIC', 'ATTITUDE', 'FORM', 'STATUSCODE',\n",
    "             'TNATIONCODE', 'TPUBLIC', 'MASTER_CUSIP', 'TTICKER']:\n",
    "    compmna[col] = compmna[col].astype('category')\n",
    "for col in ['datadate', 'DATEANN', 'DATEEFF', 'DATEFIN']:\n",
    "    compmna[col] = compmna[col].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "compmna.drop(columns=['index'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate IV based on effective date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of days from effective date to fiscal year-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "compmna['days'] = (compmna['datadate'] - compmna['DATEEFF']).dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very few observations have negative target and acquirer sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "compmna = compmna[~(compmna['a_sale']<0) & ~(compmna['t_sale']<0) & compmna['a_sale'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "compmna['IV'] = compmna['days']/365 * (abs(compmna['SALESLTM']/compmna['a_sale']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "compmna['IV'] = np.where(compmna['IV'].notnull(), compmna['IV'], \n",
    "                         compmna['days']/365 * (abs(compmna['t_sale']/compmna['a_sale'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "compmna['IV'] = np.where(compmna['IV'].notnull(), compmna['IV'], \n",
    "                         compmna['days']/365 * (abs(compmna['MV']/compmna['AMV'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "IV = compmna[['agvkey','datadate','IV']].groupby(['agvkey','datadate']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "IV = IV[IV['IV'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "IV = IV.join(compmna[['agvkey','datadate','DealNumber']]\n",
    "        .groupby(['agvkey','datadate']).count()).rename(columns={'DealNumber':'n'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>IV</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agvkey</th>\n",
       "      <th>datadate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <th>1996-12-31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380</th>\n",
       "      <th>2008-12-31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <th>2006-12-31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <th>2008-12-31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <th>2002-12-31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179132</th>\n",
       "      <th>2012-12-31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179216</th>\n",
       "      <th>2014-12-31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184321</th>\n",
       "      <th>2010-12-31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201794</th>\n",
       "      <th>2010-12-31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266163</th>\n",
       "      <th>2006-12-31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    IV    n\n",
       "agvkey datadate            \n",
       "1164   1996-12-31  0.0  1.0\n",
       "1380   2008-12-31  0.0  1.0\n",
       "1447   2006-12-31  0.0  1.0\n",
       "1478   2008-12-31  0.0  1.0\n",
       "1998   2002-12-31  0.0  1.0\n",
       "...                ...  ...\n",
       "179132 2012-12-31  0.0  2.0\n",
       "179216 2014-12-31  0.0  1.0\n",
       "184321 2010-12-31  0.0  1.0\n",
       "201794 2010-12-31  0.0  1.0\n",
       "266163 2006-12-31  0.0  1.0\n",
       "\n",
       "[189 rows x 2 columns]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IV[IV['IV']==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M&A Disclosure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = pd.read_csv('~/Dropbox/Project/cko/0_data/manual/disc.csv', parse_dates=['DATADATE'])\n",
    "disc['CIK'] = disc['CIK'].apply(lambda x: str(int(x)).zfill(10) if pd.notnull(x) else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disclosure also might need additonal data collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc.rename(columns={\"GVKEY\":\"gvkey1\", \"FYEAR\":\"year\"}, inplace=True)\n",
    "disc.set_index([\"year\", \"gvkey1\"], inplace=True, verify_integrity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3197"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(disc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Private Target Data (Chen 2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _encoding_ option allows proper string imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw = pd.read_sas('../0_data/manual/CW2019.sas7bdat', format = 'sas7bdat', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw[['gvkey','ATTITUDE']].groupby('ATTITUDE').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw['gvkey1'] = pd.to_numeric(cw['gvkey']).astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_priv_ dataset is a subset of _compmna_ that will be matched to Ciao-Wei's data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priv = sdc[(sdc['RANKVAL'].notnull()) & (sdc['TPUBLIC'] == 'Priv.')]\n",
    "priv.drop_duplicates(inplace=True)\n",
    "priv = priv[(priv['DATEEFF'] >= '1997-01-01') & (priv['DATEEFF'] <= '2013-12-31')]\n",
    "private = priv.compute()\n",
    "\n",
    "for var in ['DATEANN', 'DATEEFF']:\n",
    "    private[var] = pd.to_datetime(private[var]).astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below grabs all but 5 _MASTER_DEAL_NO_ from _private_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge by dates and names\n",
    "cw = cw.merge(private[['AMANAMES', 'DATEANN', 'DATEEFF', 'TMANAMES', 'MASTER_DEAL_NO']],\n",
    "         left_on=['ACQ_NAME', 'ANN', 'EFF', 'TRG_NAME'],\n",
    "         right_on=['AMANAMES', 'DATEANN', 'DATEEFF', 'TMANAMES'], how='left')\n",
    "col = list(cw)\n",
    "col.insert(0, col.pop())\n",
    "cw = cw[col]\n",
    "\n",
    "cw.drop(columns=['AMANAMES', 'DATEANN', 'DATEEFF', 'TMANAMES'], inplace=True)\n",
    "\n",
    "cw.drop_duplicates(inplace=True)\n",
    "\n",
    "# review dates and names of the missing\n",
    "missing = private[['MASTER_DEAL_NO', 'AMANAMES', 'DATEANN', 'DATEEFF', 'TMANAMES']].merge(cw[cw['MASTER_DEAL_NO'].isna()][['ANN', 'EFF', 'ACQ_NAME', 'TRG_NAME']],\n",
    "                                                           how='right',left_on=['DATEANN', 'DATEEFF'], right_on=['ANN', 'EFF'])\n",
    "\n",
    "missing.drop_duplicates(inplace=True)\n",
    "missing.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# manual match\n",
    "missing = missing.iloc[[0, 1, 5, 16, 24, 26, 28, 29, 39, 44, 53]][['MASTER_DEAL_NO', 'ANN', 'EFF', 'ACQ_NAME', 'TRG_NAME']]\n",
    "\n",
    "# update MASTER_DEAL_NO\n",
    "cw = cw.merge(missing, \n",
    "         left_on=['ACQ_NAME', 'ANN', 'EFF', 'TRG_NAME'],\n",
    "         right_on=['ACQ_NAME', 'ANN', 'EFF', 'TRG_NAME'], how='left', suffixes=('','_y'))\n",
    "\n",
    "cw['MASTER_DEAL_NO'] = np.where(cw['MASTER_DEAL_NO'].isna(), cw['MASTER_DEAL_NO_y'], cw['MASTER_DEAL_NO'])\n",
    "\n",
    "cw.drop(columns=['MASTER_DEAL_NO_y'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = list(cw)\n",
    "col.insert(1, col.pop())\n",
    "cw = cw[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw.to_sql('compmna', conn, index=False, if_exists='replace')\n",
    "datadate.to_sql('datadate', conn, index = True, if_exists='replace')\n",
    "qry = '''\n",
    "    select  \n",
    "        a.*, b.datadate\n",
    "    from\n",
    "        compmna a join datadate b on\n",
    "        a.gvkey1 == b.gvkey1 and a.EFF between b.lagdate and b.datadate \n",
    "    '''\n",
    "cw = pd.read_sql_query(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw['datadate'] = pd.to_datetime(cw['datadate']).astype('datetime64[ns]')\n",
    "\n",
    "cw['year'] = cw['datadate'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql('avg_sim', conn, index=False, if_exists='replace')\n",
    "cw.to_sql('cw', conn, index = False, if_exists='replace')\n",
    "qry = '''\n",
    "    select  \n",
    "        a.*\n",
    "    from\n",
    "        avg_sim a join (select distinct gvkey1, year from cw) b\n",
    "        on a.gvkey1 = b.gvkey1 and a.year = b.year\n",
    "    '''\n",
    "cw_sim = pd.read_sql_query(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_sim = cw_sim[['gvkey1', 'year', 'dt_s1', 'dt_z1', 'dt_s2', 'dt_z2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnic_industry.to_sql('tnic', conn, index=True, if_exists='replace')\n",
    "cw_sim.to_sql('cw_sim', conn, index = False, if_exists='replace')\n",
    "qry = '''\n",
    "    select  \n",
    "        a.gvkey1, a.year, a.gvkey2\n",
    "    from\n",
    "        tnic a join (select distinct gvkey1, year from cw_sim) b\n",
    "        on a.gvkey1 = b.gvkey1 and a.year = b.year\n",
    "    '''\n",
    "cw_tnic = pd.read_sql_query(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_tnic = cw_tnic.merge(df[['gvkey1', 'year', 'dt_s1', 'dt_s2', 'dt_z1', 'dt_z2']]\n",
    "                        , left_on=['gvkey2', 'year'], right_on=['gvkey1', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_tnic.drop(columns=['gvkey1_y'], inplace=True)\n",
    "cw_tnic.rename(columns={'gvkey1_x':'gvkey1'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnic_avg = cw_tnic.groupby(['gvkey1', 'year']).mean().drop(columns=['gvkey2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_sim = cw_sim.merge(tnic_avg, left_on=['gvkey1', 'year'], right_on=['gvkey1', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_sim['dt_s1'] = cw_sim['dt_s1_x'] - cw_sim['dt_s1_y']\n",
    "cw_sim['dt_z1'] = cw_sim['dt_z1_x'] - cw_sim['dt_z1_y']\n",
    "cw_sim['dt_s2'] = cw_sim['dt_s2_x'] - cw_sim['dt_s2_y']\n",
    "cw_sim['dt_z2'] = cw_sim['dt_z2_x'] - cw_sim['dt_z2_y'] \n",
    "# cw_sim = cw_sim[['gvkey1', 'year', 'dt_s1', 'dt_z1', 'dt_s2', 'dt_z2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw = cw.merge(cw_sim, left_on=['gvkey1', 'year'], right_on=['gvkey1', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw.to_stata('/Users/ohn0000/Dropbox/Project/cko/2_pipeline/cw.dta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Materiality of M&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "material = pd.read_csv('/Users/ohn0000/Project/cko/0_data/external/materiality.csv')\n",
    "material.set_index([\"year\", \"gvkey1\"], inplace=True, verify_integrity=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful since the _year_ here refers to the M&A firm-year. The _year_ in __avg_sim__ is the year competitors are identified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'material' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-177-42b11dd127ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmanual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaterial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DATADATE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CIK'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'TGTAT_ACQAT'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'TGTDVAL_ACQAT'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MD_A'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PROFORMA'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'material' is not defined"
     ]
    }
   ],
   "source": [
    "manual = disc.join(material)[['DATADATE', 'CIK', 'TGTAT_ACQAT', 'TGTDVAL_ACQAT', 'MD_A', 'PROFORMA']].sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wrds\n",
    "db = wrds.Connection(wrds_username = \"yaera\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_details_desc = db.describe_table('sdc', 'ma_details').sort_values('name')\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    print(ma_details_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|     Variable | Description                    |\n",
    "|:------------:|:-------------------------------|\n",
    "|bookvalue     |Target Book Value (\\$mil)       |\n",
    "|compete       |Competing Bidder (Y/N)          |\n",
    "|competecode   |Competing Bid Deal Code         |  \n",
    "|dateann       |Date Announced                  |\n",
    "|dateannest    |_dateann_ is estimated (Y/N)    | \n",
    "|dateeff       |Date Effective                  | \n",
    "|ebitltm       |Target EBIT LTM (\\$mil)         |\n",
    "|pct_cash      |Percentage of consideration paid in cash|\n",
    "|pct_other|Percentage of consideration paid in other then cash or stock|\n",
    "|pct_stk|Percentage of consideration paid in stock|\n",
    "|pct_unknown|Percentage of consideration which is unknown|\n",
    "|ptincltm|Target Pre-Tax Income LTM (\\$mil)|\n",
    "|salesltm|Target Sales LTM (\\$mil)|\n",
    "|rankval|Ranking Value incl Net Debt of Target (\\$mil)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run sql query below on _WRDS_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wrds\n",
    "# sdc_query = \"\"\"\n",
    "# select master_deal_no as DealNumber, \n",
    "#         bookvalue, \n",
    "#         compete, \n",
    "#         competecode, \n",
    "#         dateann, \n",
    "#         dateannest, \n",
    "#         dateeff, \n",
    "#         ebitltm, \n",
    "#         pct_cash,\n",
    "#         pct_other,\n",
    "#         pct_stk,\n",
    "#         pct_unknown,\n",
    "#         ptincltm,\n",
    "#         salesltm,\n",
    "#         rankval\n",
    "# from sdc.ma_details\n",
    "# where dateeff is not null \n",
    "# \"\"\"\n",
    "# # and master_deal_no in %(deal_no)s\n",
    "# sdc = db.raw_sql(sdc_query, date_cols=['dateann', 'dateeff'])\n",
    "# sdc.to_pickle('/home/upenn/yaera/sdc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdc = pd.read_pickle('/Users/ohn0000/Project/cko/0_data/external/sdc.pkl')\n",
    "sdc.drop_duplicates('dealnumber', inplace = True)\n",
    "sdc['dealnumber'] = sdc['dealnumber'].astype('int64')\n",
    "\n",
    "# clear up values and change dtype to 'float'\n",
    "for column in ['bookvalue', 'ebitltm', 'pct_cash', 'pct_other', 'pct_stk', 'pct_unknown', 'ptincltm', 'salesltm', 'rankval']:\n",
    "    sdc[column] = sdc[column].apply(lambda x: np.NaN if x == '*********' else (np.NaN if pd.isna(x) else (float(x.replace(',', '')) if isinstance(x, str) else float(x))))\n",
    "    sdc[column].astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdc_sub = pd.merge(sdc_link, sdc,\n",
    "                   left_index=True, right_on='dealnumber').drop('dealnumber', axis='columns')\n",
    "sdc_sub.index.name = 'dealnumber'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdc_sub.sort_values(['agvkey', 'dateeff'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdc_link['agvkey'].count() / sdc['dealnumber'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdc_sub['agvkey'].count() / sdc_link['agvkey'].count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdc_sub.profile_report(style={'full_width':True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use __compustat__ _datadate_ and gvkey to link the sdc data to the similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wrds\n",
    "db = wrds.Connection(wrds_username = 'hohn')\n",
    "\n",
    "sdc_quary = \"\"\"\n",
    "select gvkey, datadate, fyear, cusip,  cik\n",
    "from comp.funda\n",
    "where consol = %(consol)s and indfmt in %(indfmt)s and datafmt = %(datafmt)s and popsrc = %(popsrc)s and curcd in %(curcd)s\n",
    "\"\"\"\n",
    "\n",
    "parm = {'consol':('C'), 'indfmt' : ('INDL', 'FS'), 'datafmt': ('STD'), 'popsrc' : ('D'), 'curcd' : ('USD', 'CAD')}\n",
    "\n",
    "funda = db.raw_sql(sdc_quary, params = parm, date_cols = ['datadate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funda['start'] = funda['datadate'] - pd.DateOffset(months = 12) + pd.DateOffset(days = 1)\n",
    "funda['gvkey'] = funda['gvkey'].astype('int64')\n",
    "funda.set_index('gvkey', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funda.fyear = funda.fyear.astype('Int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandasql as ps\n",
    "\n",
    "sql_query = '''\n",
    "select a.*, b.datadate, b.fyear, b.cusip, b.cik\n",
    "from sdc_sub a left join funda b\n",
    "on a.agvkey = b.gvkey and a.dateeff between b.start and b.datadate\n",
    "'''\n",
    "\n",
    "newdf = ps.sqldf(sql_query, locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = list(newdf)\n",
    "for i in range(2, 6):\n",
    "    col.insert(i, col.pop(-1))\n",
    "newdf = newdf.loc[:,col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['datadate', 'dateann', 'dateeff']:\n",
    "    newdf[i] = newdf[i].astype('datetime64[ns]')\n",
    "    \n",
    "newdf['year'] = newdf['datadate'].dt.year.astype('Int16')\n",
    "for i in ['fyear', 'agvkey', 'tgvkey']:\n",
    "    newdf[i] = newdf[i].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = list(newdf)\n",
    "col.insert(col.index('datadate'), col.pop(col.index('year')))\n",
    "newdf = newdf.loc[:,col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = newdf.drop_duplicates(subset='dealnumber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf[newdf['agvkey'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf['rankval'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18994 observations with non-missing _rankval_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf['salesltm'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8055 observations with non-missing _salesltm_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(newdf['rankval'].notnull() & newdf['salesltm'].notnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6445 observations with both _rankval_ and _salesltm_ available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append similarity score between acquirer and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload = newdf[newdf['agvkey'].notnull() & newdf['tgvkey'].notnull() & newdf['year'].notnull()][['agvkey', 'tgvkey', 'year']].rename(columns={'agvkey':'gvkey1', 'tgvkey':'gvkey2'})\n",
    "upload.to_csv('/Users/ohn0000/Project/cko/2_pipeline/upload.csv', index=False)\n",
    "!scp /Users/ohn0000/Project/cko/2_pipeline/upload.csv $WRDS:/scratch/ou/hohn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this on wrds server. The __TNIC_All__ files should be uploaded in scratch beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The server killed the previous code that joins after combines all files. The current code instead loop over the files.\n",
    "\"\"\"\n",
    "# !cd /scratch/ou/hohn/TNIC_AllPairsDistrib\n",
    "# !cat tnicall1996.txt > tnicall_combined.txt\n",
    "# !for file in tnicall{1997..2017}.txt; do sed '1d' $file >> tnicall_combined.txt; done\n",
    "# !cd ~\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "atsim.py\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scp atsim.py $WRDS:~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scp $WRDS:/scratch/ou/hohn/atsim.csv /Users/ohn0000/Project/cko/2_pipeline/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = list(newdf)\n",
    "col.insert(col.index('bookvalue'), col.pop(col.index('atsim')))\n",
    "newdf = newdf.loc[:,col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV candidates\n",
    "\n",
    "The materiality measure based on deal value will be the last resort for the IV.   \n",
    "Alternatively, 2SLS using multiple IVs is feasible.\n",
    "\n",
    "Candidates\n",
    "* Max deal value\n",
    "* Sum deal value\n",
    "* Datedif between _dateeff_ and _datadate_\n",
    "    * _dateeff_ of the first M&A\n",
    "    * _dateeff_ of the largest M&A\n",
    "    * weighted average of _dateeff_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-sections\n",
    "* Similarity between acquirer and target \n",
    "    - Relation stronger in diversifying\n",
    "    - Could be more of a U-shaped relation, i.e., competitors don't follow when you move far enough\n",
    "* Average value of pre-similarities between acquirer and close competitors \n",
    "    - Prediction not clear\n",
    "* M&A performance during the completed firm-year\n",
    "    - Relation stronger when M&A was more successful <-> how do we define success of an M&A?\n",
    "* Number of close competitors of the target\n",
    "    - Potential targets are candidates of future mergers\n",
    "* How many competitors were there initially?\n",
    "    - The size of the TNIC industry"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "450px",
    "left": "1518px",
    "right": "20px",
    "top": "120px",
    "width": "382px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
