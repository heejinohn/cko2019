{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CKO JAR Revision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rpy2.rinterface #ggplot tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review TNIC-3 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import TNIC3 data from Hoberg and Philips data library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget -P ../2_pipeline/ http://hobergphillips.tuck.dartmouth.edu/idata/tnic3_data.zip\n",
    "# !unzip -q ../2_pipeline/tnic3_data.zip -d ../2_pipeline/ && rm ../2_pipeline/tnic3_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ohn0000/.virtualenvs/cko-o4Ho2HSi/lib/python3.7/site-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Hoberg and Philips TNIC3 database\n",
    "\"\"\"\n",
    "tnic = pd.read_csv('/Users/ohn0000/Project/cko/0_data/external/tnic3_data.txt', \n",
    "                   delimiter='\\t', header=0, index_col=['gvkey1', 'year', 'gvkey2'])\n",
    "tnic.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset to firms with more than 20 competitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tnic_industry = tnic_industry.groupby(level=['gvkey1', 'year']).filter(lambda x: x.size == 20)\n",
    "# tnic_industry = tnic_industry.to_frame(name='score')\n",
    "# tnic_industry.to_pickle('../2_pipeline/tnic_industry.pkl')\n",
    "\n",
    "# tnic_industry = pd.read_pickle('../2_pipeline/tnic_industry.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntnic_industry['gvkey1'] = tnic_industry['gvkey1'].apply(lambda x: str(x).zfill(6))\\ntnic_industry['gvkey2'] = tnic_industry['gvkey2'].apply(lambda x: str(x).zfill(6))\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "tnic_industry['gvkey1'] = tnic_industry['gvkey1'].apply(lambda x: str(x).zfill(6))\n",
    "tnic_industry['gvkey2'] = tnic_industry['gvkey2'].apply(lambda x: str(x).zfill(6))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remeber that _year_ in __tnic_industry__ is the base year for identifying close competitors. Accordingly, _lead1_ is the M&A year and _lead2_ is the year following M&A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Readme_tnic3.txt explains that _year_ equals the first four digits of the __compustat__ _datadate_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shift years in __tnic_industry__ to get _lead1_ adn _lead2_ similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tnic_industry.rename(columns={'score':'score_0'}, inplace=True)\n",
    "\n",
    "# for i in range(1,3):\n",
    "#     tnic_industry['score'] = np.NaN\n",
    "#     tnic_industry.index = tnic_industry.index.set_levels(tnic_industry.index.levels[1] + 1, level=1)\n",
    "#     tnic_industry.update(tnic)\n",
    "#     tnic_industry.rename(columns={'score':'score' + '_' + str(i)}, inplace=True)\n",
    "    \n",
    "# tnic_industry.index = tnic_industry.index.set_levels(tnic_industry.index.levels[1] - 2, level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tnic_industry.to_pickle('../2_pipeline/tnic_industry.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run __*tnic_industry.py*__ on _WRDS_ to update lead scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the _lead1_ and _lead2_ values are missing. Grab these values from __TNIC_Advanced__ uploaded on _WRDS_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !scp ../2_pipeline/tnic_industry.pkl tnic_industry.py $WRDS:~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download updated __*tnic_industry*__ file from WRDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !scp $WRDS:/scratch/ou/hohn/tnic_ind_update.pkl ../2_pipeline/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnic_industry = pd.read_pickle('../2_pipeline/tnic_ind_update.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average TNIC similarity score across 20-closest competitors.  \n",
    "Remeber that in __TNIC_ALL__ most of the scores equals to zero. The _z\\__ might be the more suitable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sim = tnic_industry.groupby(level=['gvkey1','year']).mean()\n",
    "avg_sim = avg_sim.join(tnic_industry.groupby(level=['gvkey1','year']).count().add_prefix(\"n_\"))\n",
    "avg_sim = avg_sim.join(tnic_industry.fillna(0).groupby(level=['gvkey1','year']).mean().add_prefix(\"z_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_sim.dropna() \n",
    "# # 55581 observations with non-missing scores\n",
    "\n",
    "# avg_sim[(avg_sim['n_score_0'] == 20) & (avg_sim['n_score_1'] == 20) & (avg_sim['n_score_2'] == 20)]\n",
    "# # 1483 observations with all 20 competitors present in TNIC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import previously constructed datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Materiality of M&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "material = pd.read_csv('/Users/ohn0000/Project/cko/0_data/external/materiality.csv')\n",
    "material.set_index([\"year\", \"gvkey1\"], inplace=True, verify_integrity=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful since the _year_ here refers to the M&A firm-year. The _year_ in __avg_sim__ is the year competitors are identified. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M&A Disclosure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = pd.read_csv('/Users/ohn0000/Project/cko/0_data/manual/disc.csv', parse_dates=['DATADATE'])\n",
    "disc['CIK'] = disc['CIK'].apply(lambda x: str(int(x)).zfill(10) if pd.notnull(x) else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disclosure also might need additonal data collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc.rename(columns={\"GVKEY\":\"gvkey1\", \"FYEAR\":\"year\"}, inplace=True)\n",
    "disc.set_index([\"year\", \"gvkey1\"], inplace=True, verify_integrity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual = disc.join(material)[['DATADATE', 'CIK', 'TGTAT_ACQAT', 'TGTDVAL_ACQAT', 'MD_A', 'PROFORMA']].sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SDC and Compustat Link File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The link file is from [Michael Ewens](https://github.com/michaelewens/SDC-to-Compustat-Mapping.git). Cite papers below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "@article{phillips2013r,\n",
    "  title={R\\&D and the Incentives from Merger and Acquisition Activity},\n",
    "  author={Phillips, Gordon M and Zhdanov, Alexei},\n",
    "  journal={The Review of Financial Studies},\n",
    "  volume={26},\n",
    "  number={1},\n",
    "  pages={34--78},\n",
    "  year={2013},\n",
    "  publisher={Society for Financial Studies}\n",
    "  }\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "@article{ewensPetersWang2018,\n",
    " title={Acquisition prices and the measurement of intangible capital},\n",
    " author={Ewens, Michael and Peters, Ryan and Wang, Sean},\n",
    " journal={Working Paper}\n",
    " year={2018}\n",
    " }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdc_link = pd.read_csv('/Users/ohn0000/Project/cko/0_data/external/dealnum_to_gvkey.csv', \n",
    "                       dtype={'DealNumber':'Int64', 'agvkey':'Int64', 'tgvkey':'Int64'}, index_col='DealNumber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading library list...\n",
      "Done\n",
      "Approximately 5489960 rows in sdc.ma_details.\n"
     ]
    }
   ],
   "source": [
    "import wrds\n",
    "db = wrds.Connection(wrds_username = \"yaera\")\n",
    "ma_details_desc = db.describe_table('sdc', 'ma_details').sort_values('name')\n",
    "# with pd.option_context('display.max_rows', None):\n",
    "#     print(ma_details_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|     Variable | Description                    |\n",
    "|:------------:|:-------------------------------|\n",
    "|bookvalue     |Target Book Value (\\$mil)       |\n",
    "|compete       |Competing Bidder (Y/N)          |\n",
    "|competecode   |Competing Bid Deal Code         |  \n",
    "|dateann       |Date Announced                  |\n",
    "|dateannest    |_dateann_ is estimated (Y/N)    | \n",
    "|dateeff       |Date Effective                  | \n",
    "|ebitltm       |Target EBIT LTM (\\$mil)         |\n",
    "|pct_cash      |Percentage of consideration paid in cash|\n",
    "|pct_other|Percentage of consideration paid in other then cash or stock|\n",
    "|pct_stk|Percentage of consideration paid in stock|\n",
    "|pct_unknown|Percentage of consideration which is unknown|\n",
    "|ptincltm|Target Pre-Tax Income LTM (\\$mil)|\n",
    "|salesltm|Target Sales LTM (\\$mil)|\n",
    "|rankval|Ranking Value incl Net Debt of Target (\\$mil)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run sql query below on _WRDS_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wrds\n",
    "# sdc_query = \"\"\"\n",
    "# select master_deal_no as DealNumber, \n",
    "#         bookvalue, \n",
    "#         compete, \n",
    "#         competecode, \n",
    "#         dateann, \n",
    "#         dateannest, \n",
    "#         dateeff, \n",
    "#         ebitltm, \n",
    "#         pct_cash,\n",
    "#         pct_other,\n",
    "#         pct_stk,\n",
    "#         pct_unknown,\n",
    "#         ptincltm,\n",
    "#         salesltm,\n",
    "#         rankval\n",
    "# from sdc.ma_details\n",
    "# where dateeff is not null \n",
    "# \"\"\"\n",
    "# # and master_deal_no in %(deal_no)s\n",
    "# sdc = db.raw_sql(sdc_query, date_cols=['dateann', 'dateeff'])\n",
    "# sdc.to_pickle('/home/upenn/yaera/sdc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdc = pd.read_pickle('/Users/ohn0000/Project/cko/0_data/external/sdc.pkl')\n",
    "sdc.drop_duplicates('dealnumber', inplace = True)\n",
    "sdc['dealnumber'] = sdc['dealnumber'].astype('int64')\n",
    "\n",
    "# clear up values and change dtype to 'float'\n",
    "for column in ['bookvalue', 'ebitltm', 'pct_cash', 'pct_other', 'pct_stk', 'pct_unknown', 'ptincltm', 'salesltm', 'rankval']:\n",
    "    sdc[column] = sdc[column].apply(lambda x: np.NaN if x == '*********' else (np.NaN if pd.isna(x) else (float(x.replace(',', '')) if isinstance(x, str) else float(x))))\n",
    "    sdc[column].astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-10-18 00:00:00')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdc['dateeff'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdc_sub = pd.merge(sdc_link, sdc, left_index=True, right_on='dealnumber').drop('dealnumber', axis='columns')\n",
    "sdc_sub.index.name = 'dealnumber'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdc_sub.sort_values(['agvkey', 'dateeff'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use __compustat__ _datadate_ and gvkey to link the sdc data to the similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading library list...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import wrds\n",
    "db = wrds.Connection(wrds_username = 'hohn')\n",
    "\n",
    "sdc_quary = \"\"\"\n",
    "select gvkey, datadate, fyear, cusip,  cik\n",
    "from comp.funda\n",
    "where consol = %(consol)s and indfmt in %(indfmt)s and datafmt = %(datafmt)s and popsrc = %(popsrc)s and curcd in %(curcd)s\n",
    "\"\"\"\n",
    "\n",
    "parm = {'consol':('C'), 'indfmt' : ('INDL', 'FS'), 'datafmt': ('STD'), 'popsrc' : ('D'), 'curcd' : ('USD', 'CAD')}\n",
    "\n",
    "funda = db.raw_sql(sdc_quary, params = parm, date_cols = ['datadate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "funda['start'] = funda['datadate'] - pd.DateOffset(months = 12) + pd.DateOffset(days = 1)\n",
    "funda['gvkey'] = funda['gvkey'].astype('int64')\n",
    "funda.set_index('gvkey', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "funda.fyear = funda.fyear.astype('Int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandasql as ps\n",
    "\n",
    "sql_query = '''\n",
    "select a.*, b.datadate, b.fyear, b.cusip, b.cik\n",
    "from sdc_sub a left join funda b\n",
    "on a.agvkey = b.gvkey and a.dateeff between b.start and b.datadate\n",
    "'''\n",
    "\n",
    "newdf = ps.sqldf(sql_query, locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = list(newdf)\n",
    "for i in range(2, 6):\n",
    "    col.insert(i, col.pop(-1))\n",
    "newdf = newdf.loc[:,col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['datadate', 'dateann', 'dateeff']:\n",
    "    newdf[i] = newdf[i].astype('datetime64[ns]')\n",
    "    \n",
    "newdf['year'] = newdf['datadate'].dt.year.astype('Int16')\n",
    "for i in ['fyear', 'agvkey', 'tgvkey']:\n",
    "    newdf[i] = newdf[i].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = list(newdf)\n",
    "col.insert(col.index('datadate'), col.pop(col.index('year')))\n",
    "newdf = newdf.loc[:,col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = newdf.drop_duplicates(subset='dealnumber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dealnumber</th>\n",
       "      <th>agvkey</th>\n",
       "      <th>cik</th>\n",
       "      <th>cusip</th>\n",
       "      <th>fyear</th>\n",
       "      <th>year</th>\n",
       "      <th>datadate</th>\n",
       "      <th>tgvkey</th>\n",
       "      <th>bookvalue</th>\n",
       "      <th>compete</th>\n",
       "      <th>...</th>\n",
       "      <th>dateannest</th>\n",
       "      <th>dateeff</th>\n",
       "      <th>ebitltm</th>\n",
       "      <th>pct_cash</th>\n",
       "      <th>pct_other</th>\n",
       "      <th>pct_stk</th>\n",
       "      <th>pct_unknown</th>\n",
       "      <th>ptincltm</th>\n",
       "      <th>salesltm</th>\n",
       "      <th>rankval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2238597</td>\n",
       "      <td>1004</td>\n",
       "      <td>0000001750</td>\n",
       "      <td>000361105</td>\n",
       "      <td>1997</td>\n",
       "      <td>1998</td>\n",
       "      <td>1998-05-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>1997-06-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2273624</td>\n",
       "      <td>1004</td>\n",
       "      <td>0000001750</td>\n",
       "      <td>000361105</td>\n",
       "      <td>1997</td>\n",
       "      <td>1998</td>\n",
       "      <td>1998-05-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>1997-10-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2570557</td>\n",
       "      <td>1004</td>\n",
       "      <td>0000001750</td>\n",
       "      <td>000361105</td>\n",
       "      <td>2000</td>\n",
       "      <td>2001</td>\n",
       "      <td>2001-05-31</td>\n",
       "      <td>1300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>2000-09-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.75</td>\n",
       "      <td>81.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.000</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3307499</td>\n",
       "      <td>1004</td>\n",
       "      <td>0000001750</td>\n",
       "      <td>000361105</td>\n",
       "      <td>2006</td>\n",
       "      <td>2007</td>\n",
       "      <td>2007-05-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>2007-04-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3419980</td>\n",
       "      <td>1004</td>\n",
       "      <td>0000001750</td>\n",
       "      <td>000361105</td>\n",
       "      <td>2007</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008-05-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>2007-12-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33059</th>\n",
       "      <td>1029741</td>\n",
       "      <td>289735</td>\n",
       "      <td>0001565228</td>\n",
       "      <td>92836Y201</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.238</td>\n",
       "      <td>3.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33060</th>\n",
       "      <td>402724</td>\n",
       "      <td>296753</td>\n",
       "      <td>0001528903</td>\n",
       "      <td>N07831105</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>2013-01-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33061</th>\n",
       "      <td>850888</td>\n",
       "      <td>314866</td>\n",
       "      <td>0001492966</td>\n",
       "      <td>G6583A102</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>2015-06-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>559.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33062</th>\n",
       "      <td>687462</td>\n",
       "      <td>315318</td>\n",
       "      <td>0001590714</td>\n",
       "      <td>28618M106</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>2014-10-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>169.854</td>\n",
       "      <td>401.553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33063</th>\n",
       "      <td>813065</td>\n",
       "      <td>316056</td>\n",
       "      <td>0001579241</td>\n",
       "      <td>G0176J109</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.700</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28481 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       dealnumber  agvkey         cik      cusip  fyear  year   datadate  \\\n",
       "0         2238597    1004  0000001750  000361105   1997  1998 1998-05-31   \n",
       "1         2273624    1004  0000001750  000361105   1997  1998 1998-05-31   \n",
       "2         2570557    1004  0000001750  000361105   2000  2001 2001-05-31   \n",
       "3         3307499    1004  0000001750  000361105   2006  2007 2007-05-31   \n",
       "4         3419980    1004  0000001750  000361105   2007  2008 2008-05-31   \n",
       "...           ...     ...         ...        ...    ...   ...        ...   \n",
       "33059     1029741  289735  0001565228  92836Y201   2016  2016 2016-12-31   \n",
       "33060      402724  296753  0001528903  N07831105   2013  2013 2013-12-31   \n",
       "33061      850888  314866  0001492966  G6583A102   2015  2015 2015-08-31   \n",
       "33062      687462  315318  0001590714  28618M106   2014  2014 2014-12-31   \n",
       "33063      813065  316056  0001579241  G0176J109   2015  2015 2015-12-31   \n",
       "\n",
       "       tgvkey  bookvalue compete  ...  dateannest    dateeff ebitltm pct_cash  \\\n",
       "0         NaN        NaN    None  ...          No 1997-06-19     NaN      NaN   \n",
       "1         NaN        NaN    None  ...          No 1997-10-24     NaN      NaN   \n",
       "2        1300        NaN    None  ...          No 2000-09-29     NaN    18.75   \n",
       "3         NaN        NaN    None  ...          No 2007-04-03     NaN      NaN   \n",
       "4         NaN        NaN    None  ...          No 2007-12-03     NaN      NaN   \n",
       "...       ...        ...     ...  ...         ...        ...     ...      ...   \n",
       "33059     NaN        NaN    None  ...          No 2016-02-01     NaN      NaN   \n",
       "33060     NaN        NaN    None  ...          No 2013-01-29     NaN      NaN   \n",
       "33061     NaN        NaN      No  ...          No 2015-06-25     NaN   100.00   \n",
       "33062     NaN        NaN    None  ...          No 2014-10-01     NaN      NaN   \n",
       "33063     NaN        NaN    None  ...          No 2015-04-01     NaN      NaN   \n",
       "\n",
       "       pct_other  pct_stk  pct_unknown  ptincltm  salesltm  rankval  \n",
       "0            NaN      NaN          NaN       NaN    45.000      NaN  \n",
       "1            NaN      NaN          NaN       NaN    18.000      NaN  \n",
       "2          81.25      NaN          NaN       NaN    20.000    0.016  \n",
       "3            NaN      NaN          NaN       NaN       NaN      NaN  \n",
       "4            NaN      NaN          NaN       NaN       NaN      NaN  \n",
       "...          ...      ...          ...       ...       ...      ...  \n",
       "33059     100.00      NaN          NaN       NaN    12.238    3.000  \n",
       "33060        NaN      NaN          NaN       NaN       NaN      NaN  \n",
       "33061        NaN      NaN          NaN       NaN       NaN  559.000  \n",
       "33062        NaN      NaN        100.0       NaN   169.854  401.553  \n",
       "33063        NaN      NaN          NaN       NaN    22.700      NaN  \n",
       "\n",
       "[28481 rows x 22 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf[newdf['agvkey'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18994"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf['rankval'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18994 observations with non-missing _rankval_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8055"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf['salesltm'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8055 observations with non-missing _salesltm_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6445"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(newdf['rankval'].notnull() & newdf['salesltm'].notnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6445 observations with both _rankval_ and _salesltm_ available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append similarity score between acquirer and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload.csv                                    100%  113KB 448.0KB/s   00:00    \n"
     ]
    }
   ],
   "source": [
    "upload = newdf[newdf['agvkey'].notnull() & newdf['tgvkey'].notnull() & newdf['year'].notnull()][['agvkey', 'tgvkey', 'year']].rename(columns={'agvkey':'gvkey1', 'tgvkey':'gvkey2'})\n",
    "upload.to_csv('/Users/ohn0000/Project/cko/2_pipeline/upload.csv', index=False)\n",
    "!scp /Users/ohn0000/Project/cko/2_pipeline/upload.csv $WRDS:/scratch/ou/hohn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this on wrds server. The __TNIC_All__ files should be uploaded in scratch beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The server killed the previous code that joins after combines all files. The current code instead loop over the files.\n",
    "\"\"\"\n",
    "# !cd /scratch/ou/hohn/TNIC_AllPairsDistrib\n",
    "# !cat tnicall1996.txt > tnicall_combined.txt\n",
    "# !for file in tnicall{1997..2017}.txt; do sed '1d' $file >> tnicall_combined.txt; done\n",
    "# !cd ~\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "atsim.py\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atsim.py                                      100%  939    19.4KB/s   00:00    \n"
     ]
    }
   ],
   "source": [
    "!scp atsim.py $WRDS:~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scp $WRDS:/scratch/ou/hohn/atsim.csv /Users/ohn0000/Project/cko/2_pipeline/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = list(newdf)\n",
    "col.insert(col.index('bookvalue'), col.pop(col.index('atsim')))\n",
    "newdf = newdf.loc[:,col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV candidates\n",
    "\n",
    "The materiality measure based on deal value will be the last resort for the IV.   \n",
    "Alternatively, 2SLS using multiple IVs is feasible.\n",
    "\n",
    "Candidates\n",
    "* Max deal value\n",
    "* Sum deal value\n",
    "* Datedif between _dateeff_ and _datadate_\n",
    "    * _dateeff_ of the first M&A\n",
    "    * _dateeff_ of the largest M&A\n",
    "    * weighted average of _dateeff_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-sections\n",
    "* Similarity between acquirer and target \n",
    "    - Relation stronger in diversifying\n",
    "    - Could be more of a U-shaped relation, i.e., competitors don't follow when you move far enough\n",
    "* Average value of pre-similarities between acquirer and close competitors \n",
    "    - Prediction not clear\n",
    "* M&A performance during the completed firm-year\n",
    "    - Relation stronger when M&A was more successful <-> how do we define success of an M&A?\n",
    "* Number of close competitors of the target\n",
    "    - Potential targets are candidates of future mergers\n",
    "* How many competitors were there initially?\n",
    "    - The size of the TNIC industry"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cko",
   "language": "python",
   "name": "cko"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
